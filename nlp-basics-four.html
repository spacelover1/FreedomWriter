<!DOCTYPE html>
<html dir="rtl" lang="fa">
  
  <head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="author" content="نویسنده" />
<meta name="copyright" content="Commons Attribution 4.0 International" />
<meta name="robot" content="" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="description" content="" />

<link rel="canonical" href="https://spacelover.ir/hello-world.html" />
<link rel="icon" href="" />
<link rel="stylesheet" href="https://spacelover.ir/assets/css/main.css" />
<link rel="stylesheet" href="https://spacelover.ir/assets/fonts/fontawesomev5.0.2.css" />
<meta name="keywords" content='nlp,اموزش' /><title>مبانی پردازش زبان طبیعی(NLP)- چهار - نویسنده آزاد</title><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>مبانی پردازش زبان طبیعی(NLP)- چهار | نویسنده آزاد</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="مبانی پردازش زبان طبیعی(NLP)- چهار" />
<meta name="author" content="نویسنده" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="مهندسی ویژگی (Feature Engineering)" />
<meta property="og:description" content="مهندسی ویژگی (Feature Engineering)" />
<link rel="canonical" href="https://spacelover.ir/nlp-basics-four.html" />
<meta property="og:url" content="https://spacelover.ir/nlp-basics-four.html" />
<meta property="og:site_name" content="نویسنده آزاد" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-07-19T00:00:00+04:30" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="مبانی پردازش زبان طبیعی(NLP)- چهار" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"نویسنده"},"dateModified":"2021-07-19T00:00:00+04:30","datePublished":"2021-07-19T00:00:00+04:30","description":"مهندسی ویژگی (Feature Engineering)","headline":"مبانی پردازش زبان طبیعی(NLP)- چهار","mainEntityOfPage":{"@type":"WebPage","@id":"https://spacelover.ir/nlp-basics-four.html"},"url":"https://spacelover.ir/nlp-basics-four.html"}</script>
<!-- End Jekyll SEO tag -->


  </head>

  <body><header>
  <div class="wrapper">
    <a class="site-title" href="https://spacelover.ir/">نویسنده آزاد</a>
    <small id="motto"> نوشته‌های یک دختر ایرانی </small>
    <!-- <nav style="display: inline;">
      <a style="color:white;" href="/test">تست برگه</a>
    </nav> -->
  </div>
</header><main>
      <div class="wrapper">

<article class="post-content">

  <div class="post-header">
    <h1 class="post-title">مبانی پردازش زبان طبیعی(NLP)- چهار</h1>
    <p>
      <i class="fas fa-calendar"></i>
      دوشنبه ۲۸ تیر ۱۴۰۰<br>
      
<!--       <i class="fas fa-stopwatch"></i>
      <h۲ id="مهندسی-ویژگی-feature-engineering"><strong>مهندسی ویژگی (Feature Engineering)</strong></h۲>

<p>خلاصه ای از جلسات قبل: تا الان یاد گرفتیم که چطوری دیتایی که یکم نامنظمه رو بخونیم. و با حذف علائم نگارشی و کلمات توقف و جدا کردن کلمات و همچنین استفاده از استمر دیتا رو تمیز کردیم. و در آخر برداری کردن دیتا رو با چند روش مختلف برای ساخت مدل یاد گرفتیم. پس ما الان یک دیتا و لیبل زده تمیز داریم که برای استفاده در مدل آماده است.<br />
حالا یک قدم تا ایجاد مدل واقعی فاصله داریم و اون مهندسی ویژگیه.</p>

<h۳ id="مهندسی-ویژگی-چیه">مهندسی ویژگی چیه؟</h۳>

<p>مهندسی ویژگی یعنی یک سری ویژگی جدید بسازیم یا از ویژگی های موجود رو طوری تغییر بدیم تا بیشترین بهره وری رو از دیتا داشته باشیم.<br />
الان که دیتا رو برداری کردیم با توجه به روشی که استفاده کردیم از یه سری ویژگی های محدود استفاده می کنه. در اینجا ویژگی هایی که می تونیم اضافه کنیم مثلا می تونه موارد زیر باشه:</p>

<ul>
  <li>طول پیام. شاید مثلا پیام های اسپم طولانی تر باشند.<br /></li>
  <li>درصد علائم نگارشی استفاده شده در پیام. شاید در پیام های واقعی خیلی از علئم نگارشی استفاده نشه.<br /></li>
  <li>تعداد کارکترهای با حروف بزرگ. چوت این دیتاست انگلیسیه می تونیم همچین ویژگی ای داشته باشیم.<br /></li>
</ul>

<p>این چند نمونه ویژگی ایه که در این دیتاست می تونیم برای تشخیص بهتر پیام های اسپم و غیراسپم استفاده کنیم.</p>

<p>و برای تغییر شکل  (transform) ویژگی های موجود در دیتا یکسری کارها و فرمول های رایج وجود داره، مثلا:</p>

<ul>
  <li>تغییرات توانی (Power transformation): مثل محاسبه جذر یا توان دو دیتا و …<br /></li>
  <li>استانداردسازی دیتا. بعضی مدل ها زمانی بهتر کار می کنند که تمام ویژگی هاشون در یک مقیاس (scale) باشه.</li>
</ul>

<p>برای نمونه دیگری از تبدیل به مثال زیر دقت کنید:<br />
تصویر سمت چپ یک نمونه دیتاست رو نشون می ده که داده ها پراکنده هستند و نمی شه ارتباط درستی پیدا کرد. در همچین مواردی که یک دنباله طولانی داریم از لگاریتم استفاده می کنیم.</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover۱/NLP-with-Python/main/۴-FeatureEngineering/FE_transformation.PNG?token=AEGZAVWA۲CDPI۵ZWFAG۳HVTA۶V۶WA" /></div>

<p>در حالت کلی برای ایجاد ویژگی باید مسئله رو به درستی درک کنیم و دید خوبی نسبت بهش پیدا کنیم، و همچنین باید خلاقیت داشته باشیم و تو ذهنمون تصور کنیم که از چی می خوایم به چی برسیم و برای رسیدن به اون هدف چه ویژگی هایی نیاز داریم. مثلا در تشخیص پیام اسپم و غیراسپم پیدا کردن تعداد حروف a در پیام ها ممکنه کمک چندانی به حل مسئله نکنه و ویژگی مناسبی برای این مسئله نباشه ولی مثلا تعداد علائم نگارشی استفاده شده یا طول پیام به نظر مفیدتر می آد.</p>

<h۲ id="تولید-ویژگی">تولید ویژگی</h۲>

<p>بریم سراغ کد: <br />
اینجا می خوایم دو تا ویژگی طول پیام و درصد علائم نگارشی در پیام رو ایجاد کنیم.</p>

<p>بعد از خوندن دیتای خام می آییم ویژگی طول پیام رو اول می سازیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>datsset['body_len'] = dataset['body'].apply(lambda x: len(x) - x.count(" "))
</code></pre></div></div>

<p>خب <code class="language-plaintext highlighter-rouge">len(x)</code> به ما طول پیام رو می ده ولی نکته ای که هست اینه که کاراکتر فاصله هم شمرده می شه. مثلا ممکنه یک پیام به طول ۱۰، نه کاراکتر فاصله داشته باشه و این نباید برابر باشه با پیامی که ده کاراکتر غیرفاصله داره. پس برای همین تعداد فاصله ها شمرده می شه و از طول کل پیام کم می شه.</p>

<p>یک ویژگی مفید دیگه هم درصد علائم نگارشی در پیام هاست. برای محاسبه ش باید یک تابع بنویسیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def count_punctuation(text):
    count = sum([۱ for char in text if char in string.punctuation])
    return round(count/(len(char) - char.count(" ")), ۳) * ۱۰۰
</code></pre></div></div>

<p>این تابع چیکار می کنه؟ اول از همه یکی یکی علائم نگارشی رو می شماره و در نهایت با تابع <code class="language-plaintext highlighter-rouge">sum()</code> این یک ها رو جمع می کنیم. قراره درصد علائم نگارشی استفاده شده در پیام رو برگردونه. مقدار <code class="language-plaintext highlighter-rouge">count</code> تعداد علائم نگارشی یک پیامه. برای محاسبه درصد باید بیاییم این مقدار رو تقسیم بر کل کاراکترهای غیرفاصله پیام کنیم. بعد چون یک مقدار اعشاری برمی گردونه برای اینکه عدد خیلی طولانی نباشه رند می کنیم عدد رو تا سه رقم اعشار نشون بده و در نهایت در ۱۰۰ ضرب می کنیم تا از حالت اعشار خارج شه.</p>

<p>کد کامل رو <a href="https://github.com/spacelover۱/NLP-with-Python/blob/main/۴-FeatureEngineering/FeatureCreation.ipynb">اینجا</a> می تونید مشاهده کنید.</p>

<h۲ id="ارزیابی-ویژگی">ارزیابی ویژگی</h۲>

<p>حالا باید بررسی کنیم که این ویژگی ها برای این دیتاست مناسبن یا نه؟ که آیا می تونیم برای استخراج اطلاعات بهتر ازشون استفاده کنیم یا نه؟ از کتابخونه matplotlib برای رسم نمودار و هیستوگرام استفاده می کنیم. از تابع <code class="language-plaintext highlighter-rouge">hist()</code> در مجموعه توابع <code class="language-plaintext highlighter-rouge">pyplot</code> استفاده می کنیم:</p>

<p>ویژگی اولی که ساختیم طول پیام بود. حدس زدیم که احتمالا پیام های اسپم طولانی ترند. بریم ببینیم این حدس درسته یا نه؟</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(۰, ۲۰۰, ۴۰)
pyplot.hist(dataset[dataset['label'] == 'spam']['body_len'], bins, alpha=۰.۵, density=True, label='spam')
</code></pre></div></div>

<p>محدوده و تعداد استوانه ها رو با <code class="language-plaintext highlighter-rouge">bin</code> مشخص می کنیم و مقادیری که می بینید به این ترتیبه: <code class="language-plaintext highlighter-rouge">bins = np.linspace(min_boundary, max_boundary, n_bins)</code>.<br />
ممکنه در کدهای قدیمی تر پارامتر <code class="language-plaintext highlighter-rouge">normed=True</code> رو ببینید که این معادل پارامتر <code class="language-plaintext highlighter-rouge">density</code> است که اینجا استفاده کردیم در نسخه های جدیدتر پایتون از این پارامتر استفاده می شه.</p>

<p>همین خط کد رو باید یرای پیام های غیراسپم هم بنویسیم تا بتونیم مقایسه کنیم.<br />
بعد از گرفتن خروجی می بینیم که پیش بینی مون درست بوده و پیام های اسپم بسیار طولانی تر از پیام های غیراسپمن. پس این ویژگی که ایجاد کردیم مناسب و مفیده.</p>

<p>برای تست ویژگی بعدی همین خط کد رو داریم فقط به جای <code class="language-plaintext highlighter-rouge">[body_len]</code> باید <code class="language-plaintext highlighter-rouge">[punct%]</code> رو بذاریم تا ببینیم طبق حدسمون پیام های اسپم بیشتر از غیراسپما علائم نگارشی دارند؟</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(۰, ۵۰, ۴۰)
pyplot.hist(dataset[dataset['label'] == 'spam']['punct%'], bins, alpha=۰.۵, density=True, label='spam')
</code></pre></div></div>

<p>و بعد از اجرای کد می بینیم که تفاوت چشمگیری در استفاده از علائم نگارشی بین پیام های اسپم و غیراسپم وجود نداره. و همونطور که در این توزیع دیده می شه یه دنباله ای در پیام های غیراسپم ایجاد شده که احتمالا باید از تبدیل (transformation) استفاده کنیم تا بهتر بتونیم تصمیم بگیریم.</p>

<p><a href="https://github.com/spacelover۱/NLP-with-Python/blob/main/۴-FeatureEngineering/FeatureCreation%۲۶Evaluation.ipynb">کد کامل این بخش</a>.</p>

<h۲ id="تبدیل-transformation">تبدیل (Transformation)</h۲>

<p>در این بخش می خوایم بررسی کنیم که دو تا ویژگی ای که ایجاد کردیم نیاز به تبدیل دارند یا نه.<br />
اولین کاری که باید انجام بدیم اینه که توزیع کاملشون رو رسم کنیم و بعد طبق اون تصمیم بگیریم. مواردی که نشون می ده تبدیل نیازه یا نه، عدم تقارن شدید، دنباله طولانی و outlierها (یعنی اون نقاطی که خیلی از توزیع اصلی دورافتادن).</p>

<h۳ id="طول-پیام">طول پیام</h۳>

<p>برای شروع <code class="language-plaintext highlighter-rouge">bins</code> رو مثل قبل تعریف می کنیم، از صفر شروع شه تا ۲۰۰ بره و ۴۰ تا bin تولید شه:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(۰, ۲۰۰, ۴۰)
pyplot.hist(dataset['body_len'], bins)
</code></pre></div></div>

<p>نیازی به پارامترای دیگه نیست چون می خوایم توزیع کلی طول پیام ها رو ببینیم، بدون توجه به لیبلشون.</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover۱/NLP-with-Python/main/۴-FeatureEngineering/length_distribution.PNG" alt="length distribution" /></div>

<p>همونطور که قبلا دیدیم طول پیام های اسپم بیشتر از غیراسپم ها بود پس این توزیع درست و با معنیه. پس این ویژگی نیازی به تبدیل نداره.</p>

<h۳ id="درصد-پیام-های-نگارشی">درصد پیام های نگارشی</h۳>

<p>برای بررسی ویژگی بعد ۲۰۰ رو به ۵۰ تغییر می دیم یعنی متن های تا ۵۰ تا علائم نگارشی رو بررسی کنه.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(۰, ۵۰, ۴۰)
pyplot.hist(dataset['punct%'], bins)
</code></pre></div></div>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover۱/NLP-with-Python/main/۴-FeatureEngineering/punct_percentage.PNG" alt="punctuation percentage" /></div>

<p>این توزیع رو همونطور که می بینید تقارن نداره مقدار زیادی از دیتا نزدیک صفر جمع شده و همینطور یک دنباله طول و دراز هم تشکیل شده که نشون می ده نیاز به تبدیل داره.</p>

<p>حالا که ویژگی هایی که نیاز به تبدیل دارند رو مشخص کردیم، باید تبدیل رو شروع کنیم.</p>

<p>تبدیل (Transformation) فرایندیه که هر داده رو در یک ستون مشخص به صورت سیستماتیک تغییر می ده (مثلا محاسبه جذر یا توان دوم هر داده) تا دیتا رو برای استفاده بهتر مدل از اون، پاکسازی کنه.</p>

<p>مجموعه تبدیلی که اینجا استفاده می کنیم بسیار رایجه و Box-Cox Power Transformations نام داره. فرم پایه این تبدیلات y به توان x است. جدول زیر این تبدیل رو برای بازه <code class="language-plaintext highlighter-rouge">[-۲,۲]</code> نمایش می ده:</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover۱/NLP-with-Python/main/۴-FeatureEngineering/cox-box-transformation.PNG" alt="cox-box transformation" /></div>

<p>حالا اگر فرض کنیم ۵۰ درصد یک متن علائم نگارشیه، در جدول بالا <code class="language-plaintext highlighter-rouge">x = ۵۰</code> می شه.</p>

<h۳ id="فرایند-تبدیل">فرایند تبدیل</h۳>

<p>۱- مشخص کردن بازه توانی <br />
۲- اعمال هر تبدیل را به هر مقدار ویژگی انتخاب شده<br />
۳- استفاده از معیارهایی برای تشخیص تبدیلی که بهترین توزیع را تولید می کند</p>

<p>بعد از بررسی ویژگی هایی که ایجاد کردیم دیدیم که ویژگی علائم نگارشی نیاز به تبدیل داره. کد اعمال تبدیل رو به این صورت می نویسیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for i in range(۱, ۶):
    pyplot.hist((dataset['punct%'])** (۱/i), bins=۴۰)
    pyplot.title('transformation: ۱/{}'.format(str(i)))
</code></pre></div></div>

<p><a href="https://github.com/spacelover۱/NLP-with-Python/blob/main/۴-FeatureEngineering/featureEngineering_transformation.ipynb">کد کامل این بخش</a></p>

<p>برای مطالعه بیشتر درباره تبدیل و مهندسی ویژگی <a href="https://towardsdatascience.com/data-transformation-and-feature-engineering-e۳c۷dfbb۴۸۹۹">این مقاله</a> رو می تونید مطالعه کنید.</p>

 دقیقه مطالعه -->
    </p>
  </div>

  <h2 id="مهندسی-ویژگی-feature-engineering"><strong>مهندسی ویژگی (Feature Engineering)</strong></h2>

<p>خلاصه ای از جلسات قبل: تا الان یاد گرفتیم که چطوری دیتایی که یکم نامنظمه رو بخونیم. و با حذف علائم نگارشی و کلمات توقف و جدا کردن کلمات و همچنین استفاده از استمر دیتا رو تمیز کردیم. و در آخر برداری کردن دیتا رو با چند روش مختلف برای ساخت مدل یاد گرفتیم. پس ما الان یک دیتا و لیبل زده تمیز داریم که برای استفاده در مدل آماده است.<br />
حالا یک قدم تا ایجاد مدل واقعی فاصله داریم و اون مهندسی ویژگیه.</p>

<h3 id="مهندسی-ویژگی-چیه">مهندسی ویژگی چیه؟</h3>

<p>مهندسی ویژگی یعنی یک سری ویژگی جدید بسازیم یا از ویژگی های موجود رو طوری تغییر بدیم تا بیشترین بهره وری رو از دیتا داشته باشیم.<br />
الان که دیتا رو برداری کردیم با توجه به روشی که استفاده کردیم از یه سری ویژگی های محدود استفاده می کنه. در اینجا ویژگی هایی که می تونیم اضافه کنیم مثلا می تونه موارد زیر باشه:</p>

<ul>
  <li>طول پیام. شاید مثلا پیام های اسپم طولانی تر باشند.<br /></li>
  <li>درصد علائم نگارشی استفاده شده در پیام. شاید در پیام های واقعی خیلی از علئم نگارشی استفاده نشه.<br /></li>
  <li>تعداد کارکترهای با حروف بزرگ. چوت این دیتاست انگلیسیه می تونیم همچین ویژگی ای داشته باشیم.<br /></li>
</ul>

<p>این چند نمونه ویژگی ایه که در این دیتاست می تونیم برای تشخیص بهتر پیام های اسپم و غیراسپم استفاده کنیم.</p>

<p>و برای تغییر شکل  (transform) ویژگی های موجود در دیتا یکسری کارها و فرمول های رایج وجود داره، مثلا:</p>

<ul>
  <li>تغییرات توانی (Power transformation): مثل محاسبه جذر یا توان دو دیتا و …<br /></li>
  <li>استانداردسازی دیتا. بعضی مدل ها زمانی بهتر کار می کنند که تمام ویژگی هاشون در یک مقیاس (scale) باشه.</li>
</ul>

<p>برای نمونه دیگری از تبدیل به مثال زیر دقت کنید:<br />
تصویر سمت چپ یک نمونه دیتاست رو نشون می ده که داده ها پراکنده هستند و نمی شه ارتباط درستی پیدا کرد. در همچین مواردی که یک دنباله طولانی داریم از لگاریتم استفاده می کنیم.</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/4-FeatureEngineering/FE_transformation.PNG?token=AEGZAVWA2CDPI5ZWFAG3HVTA6V6WA" /></div>

<p>در حالت کلی برای ایجاد ویژگی باید مسئله رو به درستی درک کنیم و دید خوبی نسبت بهش پیدا کنیم، و همچنین باید خلاقیت داشته باشیم و تو ذهنمون تصور کنیم که از چی می خوایم به چی برسیم و برای رسیدن به اون هدف چه ویژگی هایی نیاز داریم. مثلا در تشخیص پیام اسپم و غیراسپم پیدا کردن تعداد حروف a در پیام ها ممکنه کمک چندانی به حل مسئله نکنه و ویژگی مناسبی برای این مسئله نباشه ولی مثلا تعداد علائم نگارشی استفاده شده یا طول پیام به نظر مفیدتر می آد.</p>

<h2 id="تولید-ویژگی">تولید ویژگی</h2>

<p>بریم سراغ کد: <br />
اینجا می خوایم دو تا ویژگی طول پیام و درصد علائم نگارشی در پیام رو ایجاد کنیم.</p>

<p>بعد از خوندن دیتای خام می آییم ویژگی طول پیام رو اول می سازیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>datsset['body_len'] = dataset['body'].apply(lambda x: len(x) - x.count(" "))
</code></pre></div></div>

<p>خب <code class="language-plaintext highlighter-rouge">len(x)</code> به ما طول پیام رو می ده ولی نکته ای که هست اینه که کاراکتر فاصله هم شمرده می شه. مثلا ممکنه یک پیام به طول 10، نه کاراکتر فاصله داشته باشه و این نباید برابر باشه با پیامی که ده کاراکتر غیرفاصله داره. پس برای همین تعداد فاصله ها شمرده می شه و از طول کل پیام کم می شه.</p>

<p>یک ویژگی مفید دیگه هم درصد علائم نگارشی در پیام هاست. برای محاسبه ش باید یک تابع بنویسیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def count_punctuation(text):
    count = sum([1 for char in text if char in string.punctuation])
    return round(count/(len(char) - char.count(" ")), 3) * 100
</code></pre></div></div>

<p>این تابع چیکار می کنه؟ اول از همه یکی یکی علائم نگارشی رو می شماره و در نهایت با تابع <code class="language-plaintext highlighter-rouge">sum()</code> این یک ها رو جمع می کنیم. قراره درصد علائم نگارشی استفاده شده در پیام رو برگردونه. مقدار <code class="language-plaintext highlighter-rouge">count</code> تعداد علائم نگارشی یک پیامه. برای محاسبه درصد باید بیاییم این مقدار رو تقسیم بر کل کاراکترهای غیرفاصله پیام کنیم. بعد چون یک مقدار اعشاری برمی گردونه برای اینکه عدد خیلی طولانی نباشه رند می کنیم عدد رو تا سه رقم اعشار نشون بده و در نهایت در 100 ضرب می کنیم تا از حالت اعشار خارج شه.</p>

<p>کد کامل رو <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/4-FeatureEngineering/FeatureCreation.ipynb">اینجا</a> می تونید مشاهده کنید.</p>

<h2 id="ارزیابی-ویژگی">ارزیابی ویژگی</h2>

<p>حالا باید بررسی کنیم که این ویژگی ها برای این دیتاست مناسبن یا نه؟ که آیا می تونیم برای استخراج اطلاعات بهتر ازشون استفاده کنیم یا نه؟ از کتابخونه matplotlib برای رسم نمودار و هیستوگرام استفاده می کنیم. از تابع <code class="language-plaintext highlighter-rouge">hist()</code> در مجموعه توابع <code class="language-plaintext highlighter-rouge">pyplot</code> استفاده می کنیم:</p>

<p>ویژگی اولی که ساختیم طول پیام بود. حدس زدیم که احتمالا پیام های اسپم طولانی ترند. بریم ببینیم این حدس درسته یا نه؟</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(0, 200, 40)
pyplot.hist(dataset[dataset['label'] == 'spam']['body_len'], bins, alpha=0.5, density=True, label='spam')
</code></pre></div></div>

<p>محدوده و تعداد استوانه ها رو با <code class="language-plaintext highlighter-rouge">bin</code> مشخص می کنیم و مقادیری که می بینید به این ترتیبه: <code class="language-plaintext highlighter-rouge">bins = np.linspace(min_boundary, max_boundary, n_bins)</code>.<br />
ممکنه در کدهای قدیمی تر پارامتر <code class="language-plaintext highlighter-rouge">normed=True</code> رو ببینید که این معادل پارامتر <code class="language-plaintext highlighter-rouge">density</code> است که اینجا استفاده کردیم در نسخه های جدیدتر پایتون از این پارامتر استفاده می شه.</p>

<p>همین خط کد رو باید یرای پیام های غیراسپم هم بنویسیم تا بتونیم مقایسه کنیم.<br />
بعد از گرفتن خروجی می بینیم که پیش بینی مون درست بوده و پیام های اسپم بسیار طولانی تر از پیام های غیراسپمن. پس این ویژگی که ایجاد کردیم مناسب و مفیده.</p>

<p>برای تست ویژگی بعدی همین خط کد رو داریم فقط به جای <code class="language-plaintext highlighter-rouge">[body_len]</code> باید <code class="language-plaintext highlighter-rouge">[punct%]</code> رو بذاریم تا ببینیم طبق حدسمون پیام های اسپم بیشتر از غیراسپما علائم نگارشی دارند؟</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(0, 50, 40)
pyplot.hist(dataset[dataset['label'] == 'spam']['punct%'], bins, alpha=0.5, density=True, label='spam')
</code></pre></div></div>

<p>و بعد از اجرای کد می بینیم که تفاوت چشمگیری در استفاده از علائم نگارشی بین پیام های اسپم و غیراسپم وجود نداره. و همونطور که در این توزیع دیده می شه یه دنباله ای در پیام های غیراسپم ایجاد شده که احتمالا باید از تبدیل (transformation) استفاده کنیم تا بهتر بتونیم تصمیم بگیریم.</p>

<p><a href="https://github.com/spacelover1/NLP-with-Python/blob/main/4-FeatureEngineering/FeatureCreation%26Evaluation.ipynb">کد کامل این بخش</a>.</p>

<h2 id="تبدیل-transformation">تبدیل (Transformation)</h2>

<p>در این بخش می خوایم بررسی کنیم که دو تا ویژگی ای که ایجاد کردیم نیاز به تبدیل دارند یا نه.<br />
اولین کاری که باید انجام بدیم اینه که توزیع کاملشون رو رسم کنیم و بعد طبق اون تصمیم بگیریم. مواردی که نشون می ده تبدیل نیازه یا نه، عدم تقارن شدید، دنباله طولانی و outlierها (یعنی اون نقاطی که خیلی از توزیع اصلی دورافتادن).</p>

<h3 id="طول-پیام">طول پیام</h3>

<p>برای شروع <code class="language-plaintext highlighter-rouge">bins</code> رو مثل قبل تعریف می کنیم، از صفر شروع شه تا 200 بره و 40 تا bin تولید شه:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(0, 200, 40)
pyplot.hist(dataset['body_len'], bins)
</code></pre></div></div>

<p>نیازی به پارامترای دیگه نیست چون می خوایم توزیع کلی طول پیام ها رو ببینیم، بدون توجه به لیبلشون.</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/4-FeatureEngineering/length_distribution.PNG" alt="length distribution" /></div>

<p>همونطور که قبلا دیدیم طول پیام های اسپم بیشتر از غیراسپم ها بود پس این توزیع درست و با معنیه. پس این ویژگی نیازی به تبدیل نداره.</p>

<h3 id="درصد-پیام-های-نگارشی">درصد پیام های نگارشی</h3>

<p>برای بررسی ویژگی بعد 200 رو به 50 تغییر می دیم یعنی متن های تا 50 تا علائم نگارشی رو بررسی کنه.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(0, 50, 40)
pyplot.hist(dataset['punct%'], bins)
</code></pre></div></div>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/4-FeatureEngineering/punct_percentage.PNG" alt="punctuation percentage" /></div>

<p>این توزیع رو همونطور که می بینید تقارن نداره مقدار زیادی از دیتا نزدیک صفر جمع شده و همینطور یک دنباله طول و دراز هم تشکیل شده که نشون می ده نیاز به تبدیل داره.</p>

<p>حالا که ویژگی هایی که نیاز به تبدیل دارند رو مشخص کردیم، باید تبدیل رو شروع کنیم.</p>

<p>تبدیل (Transformation) فرایندیه که هر داده رو در یک ستون مشخص به صورت سیستماتیک تغییر می ده (مثلا محاسبه جذر یا توان دوم هر داده) تا دیتا رو برای استفاده بهتر مدل از اون، پاکسازی کنه.</p>

<p>مجموعه تبدیلی که اینجا استفاده می کنیم بسیار رایجه و Box-Cox Power Transformations نام داره. فرم پایه این تبدیلات y به توان x است. جدول زیر این تبدیل رو برای بازه <code class="language-plaintext highlighter-rouge">[-2,2]</code> نمایش می ده:</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/4-FeatureEngineering/cox-box-transformation.PNG" alt="cox-box transformation" /></div>

<p>حالا اگر فرض کنیم 50 درصد یک متن علائم نگارشیه، در جدول بالا <code class="language-plaintext highlighter-rouge">x = 50</code> می شه.</p>

<h3 id="فرایند-تبدیل">فرایند تبدیل</h3>

<p>1- مشخص کردن بازه توانی <br />
2- اعمال هر تبدیل را به هر مقدار ویژگی انتخاب شده<br />
3- استفاده از معیارهایی برای تشخیص تبدیلی که بهترین توزیع را تولید می کند</p>

<p>بعد از بررسی ویژگی هایی که ایجاد کردیم دیدیم که ویژگی علائم نگارشی نیاز به تبدیل داره. کد اعمال تبدیل رو به این صورت می نویسیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for i in range(1, 6):
    pyplot.hist((dataset['punct%'])** (1/i), bins=40)
    pyplot.title('transformation: 1/{}'.format(str(i)))
</code></pre></div></div>

<p><a href="https://github.com/spacelover1/NLP-with-Python/blob/main/4-FeatureEngineering/featureEngineering_transformation.ipynb">کد کامل این بخش</a></p>

<p>برای مطالعه بیشتر درباره تبدیل و مهندسی ویژگی <a href="https://towardsdatascience.com/data-transformation-and-feature-engineering-e3c7dfbb4899">این مقاله</a> رو می تونید مطالعه کنید.</p>



  
    <div id="related-posts">
      <h3>مطالب مرتبط</h3>
      <ul>
        
          <li><a href="/humanity_future_2.html">آینده بشریت (۲)</a></li>
        
          <li><a href="/less-need-more-power.html">بی‌نیازتر، قدرتمندتر</a></li>
        
          <li><a href="/how-to-behave.html">ادب از که آموختی؟ از بی‌ادبان</a></li>
        
          <li><a href="/humanity_future_1.md.html">آینده بشریت (۱)</a></li>
        
          <li><a href="/unresolved.html">مسئله حل نشده</a></li>
        
        </ul>
    </div>
  

  <small id="post-tags">
    
      <i class="fas fa-tag"></i>
      <a rel="tag" href="nlp">nlp</a>
    
      <i class="fas fa-tag"></i>
      <a rel="tag" href="اموزش">اموزش</a>
    

    <i class="fas fa-code"></i>
    
    
    <a href="https://raw.githubusercontent.com/spacelover1/FreedomWriter/master/_posts/2021-07-19-nlp-basics-four.md">سورس</a>
    
  </small>

  <nav class="pagination">
    
      <a href="/covid-19.html" class="pagination--pager" title="کرونا">قبلی</a>
    

    
      <a href="/nlp-basics-three.html" class="pagination--pager" title="مبانی پردازش زبان طبیعی(NLP)- سه">بعدی </a>
    
  </nav>

  <section>
    
  </section>

</article>
</div>
    </main><footer>

  <div class="wrapper">

    

    <p id="footer-description">هر چیزی به وقتش اتفاق میفته:)
</p>

    <ul class="social-media-list">
      
      <li>
        <i class="fab fa-github"></i>
        <a href="https://github.com/spacelover1">
          <span class="username social-media-text">Github</span>
        </a>
      </li>
      
      
      
      
      <li>
        <i class="fas fa-envelope-open"></i>
        <a href="mailto:spacelover1@gmail.com">
          <span class="username social-media-text">Email</span></a>
      </li>
      
    </ul>

    <div id="footer-extra">
      <small id="license">
  <i class="fab fa-creative-commons"></i>
  مطالب این وبلاگ تحت مجوز
  <a rel="license" href="http://creativecommons.org/licenses/by/4.0/deed.fa">
    کریتیو کامنز اتریبیوشن ۴.۰ اینترنشنال
  </a>قرار دارد.
</small>
      <a id="atom" href="https://validator.w3.org/feed/check.cgi?url=https://spacelover.ir/feed.xml"><img
          src=https://spacelover.ir/assets/img/valid-atom.png alt="[Valid Atom 1.0]"
          title="Validate my Atom 1.0 feed" /></a>
    </div>

  </div>

  <small id="build-time">Site generated on Mon, 22 Sep 2025 17:10:53 +0330</small>

</footer><script src="https://spacelover.ir/assets/js/main.js"></script>
    
  </body>
</html>