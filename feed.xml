<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
<title type="text" xml:lang="fa">نویسنده آزاد</title>
<link rel="alternate" type="text/html" href="https://spacelover.ir"/>
<link rel="self" type="application/atom+xml" href="https://spacelover.ir/feed.xml"/>
<updated>2022-11-23T21:14:45Z</updated>
<id>urn:uuid:1e7d9dd8-29e4-475d-adc5-17494fb80445</id>
<author>
  <name>نویسنده</name>
  <uri>https://spacelover.ir</uri>
  <email>spacelover1@gmail.com</email>
</author>
<rights>Commons Attribution 4.0 International</rights>

  <entry>
    <title>تولد سه سالگی بلاگ- تداوم</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/consistency.html"/>
    <id>urn:uuid:</id>
    <updated>2022-11-11T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>آبان سه سال پیش داشتم روی پایان‌نامه ارشدم کار می‌کردم و چون بلافاصله بعد از مدرسه رفتم دانشگاه و بلافاصله بعد از کارشناسی، ارشد رو شروع کردم فکر اینکه چیزی تولدی نکردم همیشه باهام بود. از زمان داشنجویی هم کار می‌کردم هم درس می‌خوندم ولی با این حال حس مصرف‌کننده بودن داشتم. می‌خواستم یه چیزی درست کنم که برای خودم باشه و همچنین مسیر طاقت‌فرسای تموم کردن ارشد رو کمی راحت‌تر کنه. و اینجا رو ساختم و شروع کردم به نوشتن در بلاگ عمومی. از ۷ سالگی، خیلی اتفاقات روزمره رو ثبت کردم و می‌کنم، اتفاقاتی که خوشحال یا ناراحتم کردن، حس و حالی از یک اتفاق که می‌خواستم با مرورش دوباره حسش کنم، تصمیماتی که برای آینده دارم، اتفاقاتی که دوست دارم بیفته، همه رو ثبت می‌کنم. نوشتن همیشه حالمو خوب کرده. یه رپر آمریکایی حرف دل منو خوب زده، دفترچه من بهترین دوست منه.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You and I been best friends, ever since I was a young kid. -NF, Notebook
</code></pre></div></div>

<p>وقتی تو دفترچه می‌نویسم فقط و فقط برای خودم می‌نویسم، اما اینجا فرصتی بهم میده تا نوشته‌هام خونده بشه توسط افرادی که نمی‌شناسم و می‌تونم فیدبک بگیرم.</p>

<p>یه چیز مهم‌تری که بهم یاد داد، پیوستگی و تداوم در کاره. اینکه اگر یه کاری رو دوست داریم باید مدام براش تلاش کنیم. مهم نیست، اگر پیشرفت کمی توش داریم:</p>

<h2 id="رهرو-آن-نيست-كه-گه-تند-و-گهي-خسته-رود">رهرو آن نيست كه گه تند و گهي خسته رود/</h2>
<h2 id="رهرو-آنست-كه-آهسته-و-پيوسته-رود">رهرو آنست كه آهسته و پيوسته رود</h2>

<p>از اونجایی که ترنسلیت داره این بیت زیبا رو اشتباه ترجمه می‌کنه،‌معادل انگلیسی‌ش رو می‌نویسم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Slow and steady wins the race. 
</code></pre></div></div>

<p>مهم اینه که در هر مسیری هستیم تداوم رو حفظ کنیم. قبلا هر چی خراب می‌شد کلا رهاش می‌کردم و یه جورایی صورت مسئله رو پاک می‌کردم. مثلا اگر به یه مشکلی تو شغلم برمی‌خوردم به جای اینکه درباره‌ش صحبت کنم از اون شرکت میومدم بیرون و دنبال یه کار جدید می‌گشتم. اما الان نمی‌ترسم از اینکه نظر و  فکرم رو بیان کنم. یک نکته‌ای رو هم بگم که همه جا مثل هم نیست و شرکت‌های قبلی این اختیار رو بهم نمی‌داد که بخوام آزادانه صحبت کنم.<br />
اما به هر حال باید صحبت کنیم و اگر چیزی ناراحتمون می‌کنه بیانش کنیم و برای رفعش تلاش کنیم. <br />
بعضی وقتا هم شاید اتفاقی بیفته که از دست ما کاری برنیاد، اون مواقع هم باید سازگاری رو یاد بگیریم و به راهمون ادامه بدیم.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Shit happens. Gotta roll with it. Adapt. -Collateral 2004
</code></pre></div></div>

<p>آدم فکر می‌کنه زمین و زمان باید از کار بیفته وقتی یه اتفاق ناخوشایند برامون میفته. مثل <a href="https://www.youtube.com/watch?v=xHa6a3FtPJg">آهنگ End of the world اسکیتر دیویس</a>.</p>

<p>یه جمله سس ماستی هم بگم زندگی مثل دوچرخه می‌مونه برای حفط تعادل باید به حرکت ادامه بدیم.<br />
و آهنگ این پست. <a href="https://www.youtube.com/watch?v=OV5_LQArLa0">“You’ll never walk alone”</a></p>

<p>تولد بلاگم مبارک!</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>زن</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/woman.html"/>
    <id>urn:uuid:</id>
    <updated>2022-10-23T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>تو ذهنمون خیلی چیزا می‌گذره و خیلی وقتا یه فکری داریم تو ذهنمون پرورش میدیم و خیلی به نظرمون قشنگ و بزرگ و عالیه ولی وقتی بیانش می‌کنیم به هر طریقی، گفتار یا روی کاغذ، می‌بینیم اونقدرا که فکر میکردیم بزرگ نبوده.<br />
با این مقدمه می‌خوام فکرامو درباره زن بنویسم.<br /></p>

<p>این دیتا براساس تعامل با خیل عظیمی از زنانی که تا به امروز به هر طریقی می‌شناسمشون مثل مادر، مادربزرگ‌ها، خاله‌ها، عمه‌ها، زن‌عموها، زن‌دایی‌ها، دختران فامیل، همسایه‌ها و البته تجربه زندگی خودم تا الانه.</p>

<p>وقتی می‌بینم یک ظلمی در حق فردی صورت گرفته واقعا خشمگین می‌شم و می‌خوام کاری انجام بدم و اگر کاری ازم برنیاد ناراحت می‌شم و این خشم سرکوب می‌شه. اما چرا نباید کاری ازم بربیاد من هر کاری بخوام می‌تونم انجام بدم ولی در ادامه با این جمله دردناک روبرو می‌شم که حرکت دفاعی یا تهاجمی من ممکنه شاید الان به نتیحه نرسه ولی برای نسل‌های بعد ممکنه نتیجه‌بخش باشه.
نمونه‌های خشونت علیه زنان:</p>

<p>رفتار نامناسب و آزاردهنده برخی مردان در محل کار. چرا باید اینطوری باشن و کی میشه که اینطوری نباشن مردا؟ بخش اعظمی البته بدلیل عدم آموزشه، ولی مورد مشابه از کشورهای پیشرفته هم گزارش شده. و همگی دیدیم و شنیدیم.</p>

<p>یکی از مردای فامیل که زن و بچه داره رفته با یک دختر ۲۹ ساله ازدواج کرده.</p>

<p>خواهری به خواهرش میگه، شوهرت هر چی گفت تو فقط سکوت کن، جوابش رو نده. چرا؟ این چه مزخرفیه؟ وقتی کسی بهت زور می‌گه و حقت داره رعایت نمی‌شه، باید چیزی نگی؟ این حماقت به دلیل نداشتن دانشه و معنیش این نیست که اگر دکترا ریاضی داشته باشی ینی این مورد رو میتونی حل کنی. دانش در مورد حقوق خودمون و اینکه چطور مرز برای دیگران تعریف کنیم و از حقوق خودمون دفاع کنیم و اجازه ندیم کسی حق‌مون رو پایمال کنه.</p>

<p>تو حیاط بیمارستان نشسته بودم و خانمی از همسرش ناله می‌کرد که نمی‌ذاره بره بیرون یا کارایی که دوست داره رو انجام بده. می‌گفت برای اینکه از محدودیت‌هایی که پدرش در خانه براش ایجاد کرده می‌خواسته رها شه و خودش رو انداخته تو چاه.</p>

<p>خانواده یکی از دوستان دبیرستانم همیشه نزدیک غروب به دخترشون زنگ میزدن پشت سر هم که باید الان خونه باشه. یه مدتی بود که با یه پسری دوست بود و بعد ازدواج کرد و دلیل اصلیش فرار از خونه و سخت‌‌گیری خانواده بود.</p>

<p>در یکی از سفرهایی که داشتم به انزلی و تنهایی داشتم لذت می‌بردم از همه‌چی، از یکی یه سوالی پرسیدم، مرد مسنی بود، گفت برای چی تنها اومدی؟ دحتر که تنها نمی‌ره سفر !!!</p>

<p>یا دختری می‌خواد بره یه خونه اجاره کنه تا مستقل زندگی کنه و خانواده‌ش بهش میگن نه یا برای چی؟ یا اگر می‌خوای مستقل شی باید ازدواج کنی. اینها چه ارتباطی به هم دارند؟ اها چرا، ارتباط عکس!</p>

<p>چند سالی می‌شه که می‌گم چرا باید روسری سر کنم؟! <br />
متاسفانه سوالات جوانان ما باید در این سطح بمونه در حالی که میتونه این انرژی صرف مسائل علمی یا علائق شخصی بشه. :/</p>

<p>تو حیاط مجتمعی که ساکن هستیم نشسته بودم و بچه‌ها داشتن بازی می‌کردن و پسرا داشتن شعر “دخترا بادکنکن دست بزنی میترکن پسرا شیرن مثل شمشیرن” رو می‌خوندن. و بهشون گفتم اصلا شعر قشنگی نیست. گفتم دوست دارین یکی به شما بگه نمی‌تونین کاری انجام بدین؟! <br />
و واقعا لعنت آسمان‌ها و زمین بر کسی که این شعر رو اولین بار ساخته.</p>

<p>رفته بودم روستایی که پدربزرگ و مادربزرگم زندگی می‌کنند و یک پسربچه ۱۰ ساله وقتی منو پشت فرمون دید گفت زن‌ها هم مگه رانندگی می‌کنند و پوزخندی زد و همینطوری زل زد بهم.</p>

<p>موفقیت و استقلال زنان نه تنها در ایران بلکه در جوامع پیشرفته هم تعریف نشده است. طوری که اگر زن بدنبال این‌ها باشه یعنی بخواد پول دربیاره، مستقل باشه و دنبال موفقیت باشه درست نیست و مانعش میشن. در مورد کشور پیشرفته، استناد به یکی از مصاحبه‌های تیلر سوئیفت.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>برای دختری که آرزو داشت پسر بود</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/for-liberty.html"/>
    <id>urn:uuid:</id>
    <updated>2022-10-20T00:00:00Z</updated>
    <category term="ایران"/><category term="آزادی"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p><img src="https://raw.githubusercontent.com/spacelover1/personalBlog/master/image/iran.png" alt="Iran" /></p>

<p>تا همین  چند سال پیش، برتری پسر به دختر یه جورایی هاردکد شده بود تو ذهنم و شاید هنوزم آثارش باقی مونده باشه. ویرایش و اصلاح این دیتای اشتباه هاردکد شده خیلی سخته و باعث اتلاف وقت زیادی میشه. و مهم‌تر از همه آسیب‌های جبران‌ناپذیری که وارد می‌کنه. چه روزا و شبایی که از دختر بودن خودم متنفر بودم و می‌گفتم کاش پسر بودم. دیتای اشتباهی که توسط یک فرهنگ ناسالم که در نظام فکری غالب جامعه ریشه دوانده. و حکومت ستمگری که از ابتدا این فرهنگ نادرست و نظام مردسالار رو شکل و ترویج داده. <br />
این تفکر که از دختر بودنت بدت بیاد دلایل متفاوتی می‌تونه داشته باشه که همشون به هم مربوطن و دلیل اصلیش می‌تونه محدودیت‌ها و تبعیض‌هایی که یک دختر متوجهش می‌شه باشه.<br /></p>

<p>این تنها یک مثال از ضربات محدودیت‌های موجود علیه زنان و دختران ایرانی‌ست و این تفکر فقط به ضرر بانوان جامعه نیست بلکه روی مردان هم اثر منفی دارد.</p>

<p>و حالا مردم ایران برای چندمین بار، در این چهل و اندی سال، برای احقاق حقوق اولیه خود و اعلام انزجار و نارضایتی از حکومت به خیابان‌ها می‌آیند. مردمی که عموما قشر نوجوان و جوان جامعه را تشکیل می‌دهند، زخمی، بازداشت و کشته می‌شوند و در مواردی بهشون تجاوز و تعرض می‌شه. تجاوز توسط ماموران امنیتی بی‌معنی‌ترین ترکیبی است که می‌توان شنید. پلیسی که باید حافظ جان مردم باشد به مردم کشور خودش تجاوز و حمله می‌کند.</p>

<p><a href="https://www.youtube.com/watch?v=z8xXiqyfBg0">آهنگ “برای”</a> رو دوست دارم و <a href="https://www.youtube.com/watch?v=HCUfgHHkLcA">رعنا منصور هم این آهنگ رو به انگلیسی خونده</a>.<br />
خواننده‌های زیادی در این اعتراضات سراسری آهنگ خوندن که چند تاشون رو اینجا می‌ذارم.</p>

<p><a href="https://www.youtube.com/watch?v=gRMIrkOaF3s">رعنا منصور- آزادی</a><br />
<a href="https://www.youtube.com/watch?v=9wPHue_dASo">رعنا منصور- زن</a><br />
<a href="https://www.youtube.com/watch?v=reM2aWlIRQc">رعنا منصور- لمس پیروزی</a><br />
<a href="https://www.youtube.com/watch?v=y9Wd0tdM-rU">مهدی یراحی- سرود زن</a><br />
<a href="https://www.youtube.com/watch?v=WNE6IGyihLI">سالار عقیلی- ایرانم</a><br />
<a href="https://www.youtube.com/watch?v=eu465bMqXFw">سیاوش قمیشی- معجزه</a><br /></p>

<p>رعنا منصور رو به تازگی باهاش آشنا شدم. خواننده ایرانی تبار که در آمریکا به دنیا اومده و بزرگ شده. امید که زنان خواننده کشورم برای دنبال کردن آرزوهایشان نیاز به ترک وطن نداشته باشند.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>مریلین مونرو</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/marilyn-monroe.html"/>
    <id>urn:uuid:</id>
    <updated>2022-10-14T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>چند روز پیش یه کلیپی تو ایسنتا دیدم که یکی از دیالوگای مریلین مونرو در فیلم Men Prefer Blondes بود و وسوسه شدم که برم اون فیلم رو ببینم. قبلا هم اسمشو شنیده بودم و می‌گفتم خب یه بازیگر زن تو هالیوود بوده دیگه. فیلم برای ۷۰ سال پیشه ولی لباس‌ها و پارچه‌هاشون و کیفیت فیلم اصلا اینو نشون نمیده که انقد قدیمی باشه. فیلم قشنگی بود، خوشم اومد هم از فیلم هم از بازی مریلین و برای همین رفتم که یه فیلم دیگه ازش ببینم. <br />
فیلم Some Like It Hot رو انتخاب کردم، اینم خوب بود ولی من خیلی نپسندیدمش و یکی از دلایلش سیاه سفید بودنش بود.</p>

<p>معمولا وقتی یه بازیگر نظرمو جلب می‌کنه میرم درباره سرچ می‌کنم تا اطلاعات بیشتری از خودش کسب کنم و وقای رفتم سراغ مونرو چیزی که نظرم رو جلب کرد طول عمرش بود، ۳۶ سالگی فوت شده و علت مرگ رو زده بود اوردوز داروی خواب‌آور (عمدی یا تصادفی). <br />
خیلی شوکه شدم و یادم اومد که تو لیست فیلماش یه فیلمی بود برای همین امسال به اسم The Mystery of Marilyn Monroe: The Unheard Tapes و کنحکاو شدم که ببینمش. یک مستند ۱ ساعت و ۴۰ دقیقه‌ای بود که برای کشف علت مرگش ساخته شده و بنظرم خوب تموم نشده و حقیقت رو نگفته ولی در کل مستند خوش ساختی بود و اطلاعات زیادی درباره مونرو در اون گفته شده.</p>

<p><strong>اسپویلر الرت:</strong> <br />
به نظر من مونرو کشته شده و احتمالا دلیلش هم کندی‌ها (Kennedy) هستن.</p>

<p>وقتی مستند رو دیدم حالم گرفته شد، چقدر ناعادلانه می‌تونه باشه این زندگی.</p>

<p>دو فیلم دیگه بعد از اون دیدم. اول Seven Year Itch و بعد How to Marry a Millionaire. <br />
هر دو فیلم رو دوست داشتم.</p>

<p>مونرو فقط زیبا نبوده،‌ واقعا برای بهتر شدن بازیگریش تلاش می‌کرده و در این کار موفق بوده. خیلی ناراحت شدم که دوران کودکی خوشی نداشته و در آخر هم اینطوری تموم شده زندگیش. ولی یادش همیشه زنده است.</p>

<p>در مستند نکاتی بود در حرفای مونرو از دیدگاه یک دختر که خیلی دوست دارم بیشتر درباره‌شون بنویسم. مثلا یه جا میگه “من نمیدونستم سکس چیه” و شاره به کودکی و تجاوزی که بهش میشه داره.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>می‌خواستم</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/i-wanted-to.html"/>
    <id>urn:uuid:</id>
    <updated>2022-09-08T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>«می‌خواستم بهت پیام بدم حالتو بپرسم»<br />
«می‌خواستم بهت بگم فلان کارو کنی بهتره»<br />
«همیشه به یادتم می‌خواستم بهت پیام بدم»<br /></p>

<p>از سوم راهنمایی باهاش آشنا شدم و هر دو جز نفرات برتر مدرسه بودیم. سه سال دبیرستان رو با هم بودیم و بعد هم بصورت کاملا اتفاقی در یک دانشگاه و در یک رشته قبول شدیم. اواخر دانشگاه فاصله گرفتیم از هم. تفکراتش متفاوت شده بود. ازدواج کزده بود و به همین دلیل فکر می‌کرد که من بیکار عالمم و اون مسئولیتی به اندازه رئیس جمهور کشور داره. چند ماه بعد وقتی ارشد قبول شدم، متوجه شدم اون هم همون دانشگاه قبول شده. و کم‌کم با گذر زمان دوباره فاصله‌مون کم شد و با هم دوست شدیم. تا وقتی دانشگاه تموم شد. دیگه خبری ازش نداشتم. چند باری ازش سراغ گرفتم و مکالمه با خوبی خوبم تموم میشد. و آخرین بار بهش گفتم که تو این مدت ندیدم تو شروع کننده مکالمه باشی، فکر می‌کنم که بودن و نبودن من برات تفاوتی نداره پس خدافظ. و اون هیچی نگفت. تا اینکه بعد از چندین ماه، چند روز پیش واتسپ پیام داده و احوالپرسی می‌کنه میگم این چند ماه کچا بودی میگه سرم شلوغ بود. دلیلش اصلا قابل قبول نبود، بعد از چند دقیقه مکالمه متوجه شدم که می‌خواد بره کربلا و برای حلالیت گرفتن پیام داده و این رو اصلا دوست نداشتم چون هدف این نبوده که از احوال من باخبر شه بلکه برای آرامش ذهن خودش بهم پیام داده.</p>

<p>وقتی به دلمون میفته یه کاری رو انجام بدیم، انجامش بدیم. انقدر نگیم می‌خواستماااا… ولی سرم شلوغ بود.</p>

<p>چندین سال می‌گذره و هیچ کاری نمی‌کنی و بعدا هم میگی می‌خواستم سرم شلوغ بود!</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Journalist and writer Oliver Burkeman shares a strategy for generosity he learned from meditation teacher Joseph Goldstein:

"Whenever a generous impulse arises in your mind – to give money, 
check in on a friend, send an email praising someone's work – 
act on the impulse right away, rather than putting it off until later.

When we fail to act on such urges, it's rarely out of mean-spiritedness, 
or because we have second thoughts about whether the prospective recipient deserves it. 
More often, it's because of some attitude stemming from our efforts to feel in control of our time. 
We tell ourselves we'll turn to it when our urgent work is out of the way, 
or when we have enough spare time to do it really well; 
or that we ought first to spend a bit longer researching the best recipients 
for our charitable donations before making any, et cetera.

But the only donations that count are the ones you actually get around to making. 
And while your colleague might appreciate a nicely worded message of praise more than a hastily worded one, 
the latter is vastly preferable to what's truly most likely to happen if you put it off, 
which is that you'll never get around to sending that message."
</code></pre></div></div>
</div>]]>
    </content>
  </entry>

  <entry>
    <title>تریلی vs پراید</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/trailer-truck-vs-kia-pride.html"/>
    <id>urn:uuid:</id>
    <updated>2022-09-07T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>چند روز پیش، با یه پراید، تو جاده بودم. جاده شلوغ بود و پر از ماشینای سنگین. بعضی جاها تریلی میومد لاین سرعت و پشت ماشین من. و با اینکه جایی در لاین‌های دیگه نبود، فاصله خیلی خیلی کمی با ماشینم داشت و پشت سر هم چراغ می‌نداخت. هر لحظه می‌ترسیدم چون اگر یه ذره هم به ماشینم می‌خورد ماشینم خورد شده بود. تریلی، از طرف دیگه هیچ ترسی نداره، خیلی آزادانه میتونه قلدری و قدرت نمایی کنه ولی یکی که ماشین سبک سوار شده از ترس جونش میاد از یه گوشه با یه سرعت کم میره. اینطوری هم زیر فشاره و هم با کلی استرس و خستگی دیرتر به مقصدش می‌رسه.</p>

<p>چیزی که اون لحظه به ذهنم رسید این بود که این صحنه شبیه جامعه فعلیه و مردها بدون هیچ ترس و ابایی آزادانه عمل می‌کنند. و دلیل این موضوع رو فیزیک بدنی و تفکر برتری مرد به زن، که در ضمیر خودآگاه و ناخوداگاه اکثر آدما هست می‌بینم.</p>
</div>]]>
    </content>
  </entry>

  <entry>
    <title>too many mind... no mind</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/no-mind.html"/>
    <id>urn:uuid:</id>
    <updated>2022-09-02T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>معمولا هر کاری میخوایم انجام بدیم هزار جور فکر میاد تو کله‌مون. وقتی میخوایم لباس بپوشیم بریم بیرون به این فکر می‌کنیم که مردم چه فکری درباره من می‌کنند اگر این لباس رو بپوشم، تو این عکسه دماغم بزرگ افتاده اینو بذارم پروفایل بقیه ازم بدشون میاد، همه دارن می‌گن فلان غذا رو سفارش بدیم اگر بگم این غذای مورد علاقه‌م نیست دیگه منو به جمع‌شون دعوت نمی‌کنند و خیلی فکرای دیگه …</p>

<p>این فکرای متفرقه که بیشترش الکی هستن و فایده‌ای ندارن باعث می‌شه از هدف اصلی دور بشیم و تمرکزمون کمتر بشه. در نتیجه دیگه با بهترین کیفیت کارمون رو انجام نمی‌دیم.</p>

<p>در فیلم آخرین سامورایی، کاپیتان الگرن (تام کروز) وقتی داره با یکی از ژاپنی تمرین می‌کنه همش حرکات اشتباه انجام میده و فرزند سامورایی میاد بهش این جمله رو میگه:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Too many mind... No mind.
</code></pre></div></div>

<p>بهش میگه حواست پیش خیلی چیزاست، پیش مردمی که تماشا می‌کنند، شمشیر، دشمن. به چیزی فکر نکن.</p>

<p><img src="https://raw.githubusercontent.com/spacelover1/personalBlog/master/image/last-samurai.jpeg" alt="Alt text" /></p>
</div>]]>
    </content>
  </entry>

  <entry>
    <title>مهندس ناک(NOC)</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/NOC-engineer.html"/>
    <id>urn:uuid:</id>
    <updated>2022-07-22T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>در حال حاضر در سمت مهندس ناک در یک شرکتی مشغول به کار هستم. مهندس ناک در شرکت‌های مختلف می‌تونه وظایف متفاوتی داشته باشه. می‌خوام کارایی که تو این سمت انجام می‌دم رو بنویسم.</p>

<p>در حال حاضر تیم ناک هفت نفره که یک نفر تیم لیدره. در اینجا کار تیم ناک به صورت شیفت‌های ۱۲ ساعته و هر دو روز در میونه. در ماه نصفش شیفت روزه و نصف دیگه شیفت شب. شیفت روز از ۸ صبح تا ۸ شب و شیفت شب از ۸ شب تا ۸ صبح. کار ناک این شرکت (و بنظرم تقریبا جاهای دیگه) بصورت ۲۴/۷ است. در این تیم، وظیفه اصلی، اطمینان از بالا بودن سرویس‌های مختلف شرکته که توسط تیم‌های شرکت تولید می‌شن.</p>

<p>معمولا آخر هفته‌ها و ایام تعطیل شیفت‌ها خلوته. اما در روزهای عادی ترافیک کاری می‌تونه خیلی بالا باشه. یک روز کاری با تحویل گرفتن شیفت از نفر قبلی شروع می‌شه. بعد از اون باید یکسری موارد رو در مانیتور داشته باشیم و همیشه تا اخر شیفت جلوی چشممون باشه. ابزارهایی که ترافیک شبکه و اینترنت دیتاسنترها رو مانیتور می‌کنه و اگر افت ترافیک یا قطعی اینترنت پیش بیاد نمایش میده. و ابزاری برای نمایش الرت‌های تیم‌های مختلف. در عین حال ابزارهایی برای ارتباط با مشتریان و اعضای داخل شرکت‌ها وجود داره. از طریق این ابزارها به سوالات مشتری پاسخ میدیم یا به تیم مربوطه انتقال میدیم. در صورتی که کار فورسی داشته باشن، مثلا سرویس داون شده باشه، در لحظه، باید از طریق آنکال‌ها پیگیری کنیم. در این حین ممکنه چند تا مشتری یک مشکل رو مطرح کنند و بعد از بررسی متوجه بشیم که اون سرویس مختل شده و اینجا فرایند مدیریت اختلال(Incident Management)باید طی شه. چند مرحله داره این فرایند: اطلاع از وقوع حادثه(Detection)- تشخیص (Analysis)- مطلع کردن نیروهای فنی(Escalation)- مطلع کردن مشتری‌های تحت تاثیر- پیگیری- پایان حادثه.</p>

<p>در بیشتر مواقع این اینسیدنت‌ها رو توسط ابزارهای مانیتورینگ میشه تشخیص داد و فرایند مدیریتش رو طی کرد. ممکنه و معمولا هم اینطوره که اینسیدنت‌ها چندین تیم رو درگیر می‌کنن. مثلا اگر شبکه مختل شه تمامی سرویس‌هایی که در بستر شبکه دارن کار می‌کنن مختل می‌شن. 
مسئله دیگری که پیش میاد درخواست تغییراتیه (Change Request) که تیم‌ها ثبت می‌کنند. تغییرات می‌تونه نرم‌افزاری باشه، مثل اپگرید یه نرم‌افزار روی سرویس یا سخت‌افزاری باشه مثل تعویض یک ماژول خراب در سرور. این تغییرات چندین دسته‌بندی داره مثلا اینکه مشتری رو تحت تاثیر قرار میده یا خیر و یا اینکه چقدر فورسه.</p>

<p>این پست فعلا باشه تا اینجا تا در فرصت‌های اتی اپدیتش کنم.</p>
</div>]]>
    </content>
  </entry>

  <entry>
    <title>از کجا میای؟</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/where-do-you-come-from.html"/>
    <id>urn:uuid:</id>
    <updated>2022-07-19T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>چیزی که می‌خوام در باره‌ش بنویسم شاید یکم گنگ باشه. <br />
در انجام هر کاری قصد و نیتی وجود داره ولی اینکه این نیت از کجا و چی و چطور نشات گرفته شده مهمه. اینکه چه حسی داری وقتی اقدام به انجام یه کار می‌کنی. مثلا دنبال کار هستی، اولین و اصلی ترین دلیل کار کردن گذران زندگیه، اما اینکه در چه استیتی هستی موقع دنبال کار گشتن روی خیلی چیزا موثره که مهمترینش همون کار پیدا کردنه. مثلا ممکنه انقدر ضعیف شده باشی که فقط دنبال پول باشی یا ممکنه در حال حاضر یه شغلی داشته باشی ولی دنبال پیشرفت باشی. در حالت اول حاضری هر کاری انجام بدی، غیر مرتبط با رشته و علاقه و کلا هدفتو یادت میره. هدفت میشه پول دراوردن به هر قیمتی. اون موقع‌س که معیارهات رو فراموش می‌کنی و ارزش خودتو نمیدونی. طبیعیه، چون برای بقای خودت داری می‌جنگی. باید نیازهای اولیه‌ت رو برطرف کنی. اون موقع کی به ارزش و معیار فکر می‌کنه؟!</p>

<p>اما در حالت دوم دیگه نیازهای اولیه‌ برطرف شده. به فکر رسیدن به اهدافی هستی که چندین سال براش زحمت کشیدی یا شاید هم هنوز سینیور نباشی ولی از لحاظ خانوادگی و شخصیتی در مرحله‌ای باشی که فرصت سنجیدن اپشنهای مختلف رو داشته باشی بدون اینکه معیارهاتو زیرپا بذاری.</p>

<p>سعی کنیم همیشه در انجام هر کاری به وضعیت ذهنی‌مون توجه کنیم. بعضی وقتا نمی‌شه، باید معیارها رو یکم نادیده گرفت و شاید اصن معیارهامون خیلی فضایی باشن. ولی به هر حال اگر عجله نکنیم و یکم بیشتر صبر و تحمل داشته باشیم وضعیت خوب می‌شه. فقط باید یکم شرایط سختی که داریم رو تحمل کنیم و برای درومدن از چاله، خودمونو تو چاه نندازیم.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>Big Picture, Please!</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/big-picture.html"/>
    <id>urn:uuid:</id>
    <updated>2022-05-29T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>عنوان این پست از دیالوگای سریال فرندز گرفته شده. روز مراسم عروسی چندلر و مونیکا چندلر از حجم زیاد مسئولیتی که قراره گردنش بیفته قالب تهی می‌کنه و غیبش میزنه. یه جورایی همیشه اینطوری بوده و از مسئولیت زیاد شونه خالی می‌کرده. بعدش که پیداش می‌کنن و کم‌کم حاضر می‌شه برای مراسم، خبر اشتباه بهش می‌رسه که مونیکا بارداره. دوباره غیبش میزنه و وقتی پیداش می‌کنن میگه رفته بود سیگار بخره ولی تو فروشگاه وقتی لباس بچه رو می‌بینه ترسش می‌ریزه. این قدم خیلی بزرگیه برای شخصی که این همه از مسئولیت ابا داره ولی دوستاش وقتی می‌فهمن رفته بوده سیگار بخره زوم می‌کنن روی سیگار خریدنش. و چندلر می‌گه BIG PICTURE, PLEASE!</p>

<p>کاری که خیلی از ماها درباره خودمون می‌کنیم. روی لحظه حالمون تمرکز می‌کنیم اونم زمانی که در وضعیت خوبی نیستیم. و با خودمون فکر می‌کنیم که هیچ کاری نکردیم تا حالا و کلا خودمونو می‌کوبیم.</p>

<p>مراحلی که در زندگی طی می‌کنیم رو اگر مثل تصویر یا قطعات پازل در نظر بگیریم، وقتی خیلی فوکوس کنیم روش دید خوبی نخواهیم داشت. اما اگر چند قدم بیاییم عقب‌‌تر متوجه می‌شیم که همیشه وضعیت بدی نداشتیم، زمان‌هایی هم بوده که بهترین خودمون بودیم یا اتفاقای خوبی افتاده برامون یا حس و حال خوبی داشتیم.</p>

<p>‍‍‍
    <code class="language-plaintext highlighter-rouge">BIG PICTURE, PLEASE!</code></p>
</div>]]>
    </content>
  </entry>

  <entry>
    <title>فیلم c'mon, c'mon</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/cmon-cmon.html"/>
    <id>urn:uuid:</id>
    <updated>2022-05-08T00:00:00Z</updated>
    <category term="فیلم"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p>تو <a href="https://www.imdb.com/title/tt10986222/">این فیلم</a> شخصیت اصلی ینی Joaquin Phoenix با بچه ها درباره آینده و افکارشون مصاحبه می کنه. مثل همیشه چند تا از دیالوگ های فیلم رو میذارم. این دیالوگ ها اکثرا صحبت بجه های توی فیلمه.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>So my fear is loneliness, and people not understanding you even though they're there to understand  
you. It's just really scary cause feels like you have no one.
</code></pre></div></div>

<hr />

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>She says: Even though we love each other, she'll never know everything about me and I'll never  
know everything about her. It's just the way it is.
</code></pre></div></div>

<hr />

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Have you ever thought about future?"
"Oh, yeah. Whatever you plan on happening, never happens. Stuff you would never think of happens.  
So you just have to come on. Come on, come on, come on, come on..."
</code></pre></div></div>

<hr />

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'Kids tend to think freely. Adults when they think, they think in a tight space.' 
</code></pre></div></div>

<hr />

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Motherhood is the place in our culture where we bury our conflicts and what it means to be fully  
human. Mothers are scapegoats for personal and political failings and for everything that is wrong  
in the world. In doing this, we blind ourselves to the world’s iniquities.  
What are we doing to our mothers and we expect them to carry the burden of everything that is hard  
as to contemplate about our society and ourselves. Mothers cannot help but be in touch with the  
most difficult aspects of any fully lived life. Why on earth should've fault them to paint things  
bright and innocent and safe?"
</code></pre></div></div>

<hr />

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Over the years, you will try to make sense of that happy, sad, full, empty, always shifting life  
you're in. And when the time comes to return to your star, it may be hard to say goodbye to that  
strangely beautiful world." 
</code></pre></div></div>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>یه چیزی بگو، هر چی!</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/say-something-anything.html"/>
    <id>urn:uuid:</id>
    <updated>2022-04-04T00:00:00Z</updated>
    
    <content type="html">
      <![CDATA[<div dir="rtl"><p>مدت زیادیه که پستی ننوشتم، بخشیش بخاطر مشغله‌های زندگی و بخشیش هم بدلیل تنبلی!</p>

<p>این مدت یک شرکت عوض کردم در کل سال 1400 در سه تا شرکت مختلف بودم که الان تو سومی‌شم. یک پست درباره سوابق کاری و مصاحبه‌ها و این‌ مسائل می‌نویسم حتما.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>خودتو دوست داشته باش ینی چی؟</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/how-to-love-myself.html"/>
    <id>urn:uuid:</id>
    <updated>2021-12-31T00:00:00Z</updated>
    <category term="خودشناسی"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p>چند روز پیش سر یه کلاسی بودم که استاد به یکی از بچه‌ها گفت برای اینکه کسی تو رو دوست داشته باشه اول از همه باید خودت خودتو دوست داشته باشی. دوست داشته شدن لیاقت می‌خواد. این حرف رو قبلا هم شنیده بودم. با خودم فک می‌کردم چطوری خودمو دوست داشته باشم. یکم درباره‌ش خوندم و برای اینکه یادم بمونه و تمرین کنم می‌خوام اینجا هم بنویسم درباره‌ش.<br />
سایتی که در این پست به عنوان <a href="https://www.healthline.com/health/13-self-love-habits-every-woman-needs-to-have">منبع</a> ازش استفاده می‌کنم ضمایر مخاطب استفاده کرده ولی من ضمایر رو به خودم برگردوندم. شما هم اگر دوست داشتین این موارد رو امتحان کنید.</p>

<h2 id="خودم-رو-با-کسی-مقایسه-نمیکنم">خودم رو با کسی مقایسه نمی‌کنم</h2>

<p>اینکه فلان شخص در فلان شرکت کار می‌کنه هیچ ارتباطی به من نداره. هر شخصی زندگی خودشو داره از اول و این باعث می‌شه که هر کدوممون تک و منجصر به فرد باشیم. بنابراین مقایسه بخشی از زندگی افراد دیگه با خودمون کاملا بی معنیه. من انرژی و تمرکزمو میذارم روی بهتر شدن خودم و انجام کارایی که دوست دارم.</p>

<h2 id="نگران-افکار-بقیه-نیستم">نگران افکار بقیه نیستم</h2>

<p>اینکه بقیه چه فکری درباره من می‌کنن مهم نیست. من نباید بقیه رو راضی نگه دارم. انرژی من باید صرف شاد کردن خودم بشه.</p>

<h2 id="به-خودم-اجازه-اشتباه-کردن-میدم">به خودم اجازه اشتباه کردن می‌دم</h2>

<p>اکثر کارایی که الان توشون قوی شدم بخاطر اشتباهاتی بوده که قبلا انجام دادم. وقتی یه کاری رو تا حالا انجام ندادیم، احتمال زیاد اولین بار اشتباه می‌کنیم و بخاطر اون اشتباه روش درست رو یاد می‌گیریم و خیلی چیزای دیگه. <br />
پس دست به کار می‌شم و از اشتباه نمی‌ترسم.</p>

<h2 id="ظاهر-من-ارزش-من-رو-تعیین-نمیکنه">ظاهر من، ارزش من رو تعیین نمی‌کنه</h2>

<p>من لباسی رو می‌پوشم که توش حس خوبی دارم.</p>

<h2 id="افراد-سمی-رو-از-زندگیم-حذف-میکنم">افراد سمی رو از زندگیم حذف می‌کنم</h2>

<p>از آدمایی که حس خوبی ازشون نمی‌گیرم و انرژی بیهوده ازم می‌گیرن فاصله می‌گیرم تا جا برای اونایی که ارزش دوستی با من رو دارن باز بشه.</p>

<h2 id="ترسهام-رو-پردازش-میکنم">ترس‌هام رو پردازش می‌کنم</h2>

<p>بررسی احساس ترس و اضطراب باعث می‌شه ریشه مشکلات پیدا شهتا بتونیم حلشون کنیم.</p>

<h2 id="میدونم-که-بهترین-تصمیمات-رو-میگیرم">می‌دونم که بهترین تصمیمات رو می‌گیرم</h2>

<p>هر کسی خودش، خودش رو بهتر می‌شناسه و می‌دونه چی حالشو خوب می‌کنه.<br />
یه قانونی که برای خودم دارم اینه که اگر جوابم در انجام کاری “نمی‌دونم” بود انجامش نمی‌دم تا زمانی که به اطمینان برسم.</p>

<h2 id="از-هر-فرصتی-که-پیش-میآد-استفاده-میکنم-یا-خودم-فرصت-میسازم">از هر فرصتی که پیش می‌آد استفاده می‌کنم یا خودم فرصت می‌سازم</h2>

<p>اگر نگران فکر بقیه نباشیم و از اشتباه نترسیم می‌تونیم از این فرصت‌ها استفاده کنیم.
من اگر دوست داشته باشم با کسی صحبت کنم باهاش تماس می‌گیرم و منتظر اون نمی‌شم.
یا اگر دوست داشته باشم تو یه جمع جدیدی باشم، باهاشون صحبت می‌کنم و اگر دوست داشتن اونوقت دوستای جدید پیدا می‌کنیم :)</p>

<h2 id="خودم-رو-در-اولویت-میذارم">خودم رو در اولویت می‌ذارم</h2>

<p>علائق خودم رو (به موقعش) در اولویت می‌ذارم و برای خودم ارزش قائل هستم.</p>

<h2 id="درد-و-شادی-رو-حس-میکنم">درد و شادی رو حس می‌کنم</h2>

<p>به احساسات مختلف اجازه بروز می‌دم و درکشون می‌کنم.
یه موردی رو هم بگم: هر زمانی احساس افسردگی داشتین ورزش کنید و ساعت خوابتونو تنظیم کنید. صبح زود بیدار شید و شب به موقع بخوابید.
هر زمانی هم احساس شیدایی داشتین یعنی خوشحالی و انرژی زیاد سعی کنید بخوابید و کمتر تحرک داشته باشید.</p>

<h2 id="نظراتم-رو-در-جمع-بیان-میکنم">نظراتم رو در جمع بیان می‌کنم</h2>

<p>نظر هر شخصی محترم و مهمه همینطور نظر من. وقتی یه سوالی مطرح می‌شه نظرم رو بیان می‌کنم بدون ترس از قضاوت. مهم نیس بقیه چه فکری می‌کنن. یه نکته‌ای که وجود داره اینه که اصولا بقیه فکری درباره شما نمی‌کنن. شما خودت فک کن چقدر به بقیه فک می‌کنی؟ خیلی کم. ادما بیشتر متمرکز هستن روی اعمال خودشون.</p>

<h2 id="زیبایی-رو-در-چیزای-کوچیک-ببینیم">زیبایی رو در چیزای کوچیک ببینیم</h2>

<p>قدردان زیبایی‌ها و چیزایی که حس خوبی بهم می‌ده هستم و این باعث می‌شه بیشتر زیبایی ببینم و جذب کنم.</p>

<h2 id="با-خودم-مهربونم">با خودم مهربونم</h2>

<p>همینطوری در طول روز همه دارن از ادم انتقاد می‌کنن و به ادم حرف می‌زنن. من خودم با خودم مهربون هستم و از کلمات خوب برای توصیف خودم استفاده می‌کنم.
من تا الان که زندگی کردم خیلی کارای باارزش و قشنگ انجام دادم و از این به بعد هم به ارزش افرینی‌ها ادامه می‌دم. برای همین ذهن زیبا به خودم افتخار می‌کنم و از خودم ممنونم.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>هنگام رانندگی به جای نایس بودن، قابل پیش بینی باشیم</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/driving-rules.html"/>
    <id>urn:uuid:</id>
    <updated>2021-12-30T00:00:00Z</updated>
    <category term="رانندگی"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p>در ردیت یک سابی وجود داره با عنوان <a href="https://www.reddit.com/r/IdiotsInCars/">IdiotsInCars</a> در اینجا ویدیوهای متفاوتی (معمولا در امریکا) از اشتباهات رانندگی به اشتراک گذاشته می شه. بعضیاش خنده دار و فانه، یه سری حماقت های رانندگی، یه سری هم کارهای خطرناک. یه جمله ای که خیلی اوقات تو کامنتا تکرار میشه اینه: be predictable not nice. مثلا وقتی یکی از فرعی می‌خواد وارد اصلی بشه باید صبر کنه و توقف کامل داشته باشه اگر خیابون خالی بود و راه داشت می‌تونه بپیچه. شخصی هم که داره در خیابان اصلی رانندگی می‌کنه نباید بخاطر ماشینی که از فرعی میاد توقف کنه چون ممکنه باعث تصادف بشه. یک مورد دیگه‌ای که متوجه شدم اینکه در اکثر ایالت‌ها کسی که از پشت بزنه به ماشین جلویی حتما مقصر نیست و مقصر راننده‌ایه که توقف داشته در مسیری که نباید. برعکس ایران که هر ماشینی از پشت بزنه بهت مقصره.</p>

<h2 id="خطهای-سفید-در-خیابانها-بیدلیل-نیست">خط‌های سفید در خیابان‌ها بی‌دلیل نیست</h2>

<p>یک موردی که خیلی برام آزاردهنده است موقع رانندگی تو تهران اینه که اتوبان سه لاینه طراحی شده، ولی شما 5 لاین ماشین می‌بینید! ماشین‌هایی که در لاین‌های کناری هستن طوری رانندگی می‌کنن که یک سانت با گاردریل فاصله دارن تا جا باز بشه برای ماشینای دیگه که بیان روی خط‌ها رانندگی کنن!!!! واقعا این چه منطق و دلیلی داره؟ چرا اینطوری رانندگی می‌کنند من متوجه نمی‌شم. این کار هیچ جوره قابل توجیه نیست. ترافیکه؟ خب برای همه است شما اگر با نظم رانندگی کنی هم تصادف کمتر می‌شه هم زودتر می‌رسی. خط‌ها استاندارد نیست؟ خیر کاملا استاندارده، قرار نیست خط‌ها فیت ماشین شما باشه تا ماشین‌ها در لاین‌ها به هم بچسبن. <br />
کاری که من انجام می‌دم اینه که در یک لاین طوری رانندگی می‌کنم که باید. یعنی نمی‌رم بچسبم به ماشین بغلی تا لاین باز شه. تو لاین خودم حرکت می‌کنم و اینطوری ماشین‌های پشتی هم حداقل تو لاین من مرتب می‌شن. امیدوارم تعداد بیشتری افراد به این خط‌ها توجه کنند.</p>

<h2 id="از-چراغهای-راهنمای-خودرو-استفاده-کنیم">از چراغ‌های راهنمای خودرو استفاده کنیم!</h2>

<h2 id="در-رانندگی-مثل-بقیه-کارها-نگاه-جنسیت-زده-نداشته-باشیم-حتی-شما-خانم-محترم">در رانندگی (مثل بقیه کارها) نگاه جنسیت زده نداشته باشیم. حتی شما خانم محترم!</h2>
</div>]]>
    </content>
  </entry>

  <entry>
    <title>معرفی یک آهنگ، یک کتاب و یک سایت</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/suggestions.html"/>
    <id>urn:uuid:</id>
    <updated>2021-12-10T00:00:00Z</updated>
    <category term="معرفی"/><category term="کتاب"/><category term="اهنگ"/><category term="سایت"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p>زمانی که کرونا گرفتم به حدی ضعیف شده بودم که فکر می‌کردم دیگه هیچ‌وقت خوب نمی‌شم، اما تو این مدت حالم بهتر شد و تونستم دوباره برم طناب بزنم و با بچه‌ها فوتبال بازی کنم و دیشب هم نزدیک یک ساعت دوچرخه‌سواری کردم. در این پست یک آهنگ یک کتاب و یک وبسایت معرفی شده، احتمالا این شیوه رو به کار ببرم و همچین پستی رو باز هم داشته باشیم. به نظرم ایده خوبیه :)</p>

<h2 id="آهنگ-enemy">آهنگ Enemy</h2>

<p>در این پست می‌خوام یکی از آهنگ‌های گروه Imagine Dragons رو معرفی کنم. آهنگ جدیده و محتواش عالی. یه جورایی همه این رو حس کردن. <a href="https://www.youtube.com/watch?v=D9G1VOjN_84"><u>لینک آهنگ Enemy</u></a> و این هم <a href="https://www.youtube.com/watch?v=4TKDGCBbD2s"><u>لینک این آهنگ در یکی از کنسرت‌ها</u></a>. خیلی خوووبه. شرکت در این کنسرت‌ها را برای همه آرزو می‌کنم :)</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tell you you're the greatest
But once you turn they hate us
</code></pre></div></div>

<p>هر فرد بنا بر تجربیاتش، برداشت خودش رو از هر آهنگ داره. برداشت من از این آهنگ اینه که اکثر آدما تا وقتی باهاتن و دوست دارن که طبق سلیقه اون‌ها عمل کنی. زمانی که خلاف میلشون باشه ازت بدشون میاد. (not that anyone cares, but people love to be loved)</p>

<p>دوست دارم برداشت‌های شما رو هم بدونم.</p>

<h2 id="کتاب-emotional-blackmail">کتاب Emotional Blackmail</h2>

<p>خوندن <a href="https://www.amazon.com/Emotional-Blackmail-People-Obligation-Manipulate/dp/0060928972">این کتاب</a> به همه توصیه می‌شه. تا الان نصفش رو خوندم. تا اینجایی که خوندم کتاب شامل یکسری داستان از مراجعه کننده‌های خانم فوروارده که با هدف گرفتن نقاط ضعف طرف مقابل که معمولا هم افراد نزدیک به انها هستند را مجبور به انجام کاری می‌کنند. &lt;/br&gt;
شاید این حس را تجربه کرده باشید که وقتی فرد نزدیکی از شما چیزی می‌خواهد که خلاف میل شماست یا آن کار را انجام می‌دهید که او را خشنود نگه دارید و یا زمانی که انجامش نمی‌دهید حس خیلی بدی دارید و با خود می‌گویید کاش چیزی که می‌خواست را براورده نمی‌کردم. اگر اینطوره حتما این کتاب رو بخونید.</p>

<h2 id="وبسایت-ludwig">وبسایت Ludwig</h2>

<p>بعضی وقتا هنگام نوشتن متن انگلیسی ممکنه یک ترکیبی استفاده کنید که مطمئن نباشید درسته و استفاده می‌شه یا نه. می‌تونید اون ترکیب چند کلمه‌ای رو به این وبسایت بدید و <a href="https://ludwig.guru/"><u>این وبسایت</u></a> با جستجوش در منابع مختلف انگلیسی زبان مثل New York Times یک سری جملات با این ترکیب برمی‌گردونه و شما نحوه استفاده از اون کلمات رو در جملات یاد می‌گیرید.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>کرونا</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/covid-19.html"/>
    <id>urn:uuid:</id>
    <updated>2021-09-01T00:00:00Z</updated>
    <category term="زندگی"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p>تقریبا دو هفته پیش، شب قبل از خواب لرز گرفتم فرداش وقتی بیدار شدم تب و لرز داشتم. <br />
تا سه چهار شب تب و لرز داشتم و کم کم بدنم ضعیف شد یعنی توانی نداشتم دیگه. انگار یه چیزی داره تمام ویتامینای بدن رو نابود می‌کنه و هر چی انرژیه از بدن می‌گیره. <br />
انقدر بدنم ضعیف شده بود و احساس ناتوانی داشتم که تا همین دو روز پیش حس می‌کردم دیگه هیچ‌وقت مثل قبل نمی‌شم و همیشه ضعیف می‌مونم. حس بدیه. بعد از یک هفته حس چشایی و بویاییم رو از دست دادم. حس بویایی به کل از بین رفته ولی مزه‌های اصلی رو متوجه می‌شم، مثل شور و شیرین و تند. اما مزه غذا رو به صورت کلی و مثل قبل نمی‌فهمم.
خوشبختانه ریه‌های من درگیر نشد ولی خب مشکلات دیگه بوجود آورد، مثل درد عضلات و ماهیچه‌ها.
سیستم گوارش هم تا حدودی مختل کرده.</p>

<p>این مدت کار زیادی انجام ندادم و از خیلی کارهام هم عقب افتادم و حتی انگیزه ام رو از دست دادم. بیشتر با اینترنت و فیلم و آهنگ خودم رو سرگرم کردم.</p>

<p>مینی سریال Queen’s Gambit رو دیدم. خوب بود ولی خیلی دوست نداشتم.<br />
بعضی قسمت های ریک و مورتی  و سریال کامیونیتی رو دوباره دیدم.</p>

<p>با Skeeter Davis آشنا شدم، یه خواننده قدیمی آمریکایی که سبک آهنگاش کانتریه و من خیلی ازش خوشم اومد. یکی از معروف ترین آهنگاش <a href="https://www.youtube.com/watch?v=xHa6a3FtPJg">End of the World</a>. خیلی از آهنگاش خوشم میاد. یکی دیگه از آهنگای قشنگش I want go where nobody knows me. حسی که الان دارم و چیزی که الان می خوام.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>I want to go where no one knows me
Where I can start my life anew

I want to go where no one knows me
My soul is sick my heart is sore
I want to go where all are strangers
I don't believe in friends no more
</code></pre></div></div>

<p>این روزا هم شطرنج بازی می کنم و تو یوتوب و ردیت می چرخم. اگر روزا رو همینطوری سپری کنم خروجی نهایی همین وضعیت الانه:/ این پست رو با یک نقل قول تموم می کنم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"The strong do what they can and the weak suffer what they must."
</code></pre></div></div>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>مبانی پردازش زبان طبیعی(NLP)- چهار</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/nlp-basics-four.html"/>
    <id>urn:uuid:</id>
    <updated>2021-07-19T00:00:00Z</updated>
    <category term="nlp"/><category term="اموزش"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><h2 id="مهندسی-ویژگی-feature-engineering"><strong>مهندسی ویژگی (Feature Engineering)</strong></h2>

<p>خلاصه ای از جلسات قبل: تا الان یاد گرفتیم که چطوری دیتایی که یکم نامنظمه رو بخونیم. و با حذف علائم نگارشی و کلمات توقف و جدا کردن کلمات و همچنین استفاده از استمر دیتا رو تمیز کردیم. و در آخر برداری کردن دیتا رو با چند روش مختلف برای ساخت مدل یاد گرفتیم. پس ما الان یک دیتا و لیبل زده تمیز داریم که برای استفاده در مدل آماده است.<br />
حالا یک قدم تا ایجاد مدل واقعی فاصله داریم و اون مهندسی ویژگیه.</p>

<h3 id="مهندسی-ویژگی-چیه">مهندسی ویژگی چیه؟</h3>

<p>مهندسی ویژگی یعنی یک سری ویژگی جدید بسازیم یا از ویژگی های موجود رو طوری تغییر بدیم تا بیشترین بهره وری رو از دیتا داشته باشیم.<br />
الان که دیتا رو برداری کردیم با توجه به روشی که استفاده کردیم از یه سری ویژگی های محدود استفاده می کنه. در اینجا ویژگی هایی که می تونیم اضافه کنیم مثلا می تونه موارد زیر باشه:</p>

<ul>
  <li>طول پیام. شاید مثلا پیام های اسپم طولانی تر باشند.<br /></li>
  <li>درصد علائم نگارشی استفاده شده در پیام. شاید در پیام های واقعی خیلی از علئم نگارشی استفاده نشه.<br /></li>
  <li>تعداد کارکترهای با حروف بزرگ. چوت این دیتاست انگلیسیه می تونیم همچین ویژگی ای داشته باشیم.<br /></li>
</ul>

<p>این چند نمونه ویژگی ایه که در این دیتاست می تونیم برای تشخیص بهتر پیام های اسپم و غیراسپم استفاده کنیم.</p>

<p>و برای تغییر شکل  (transform) ویژگی های موجود در دیتا یکسری کارها و فرمول های رایج وجود داره، مثلا:</p>

<ul>
  <li>تغییرات توانی (Power transformation): مثل محاسبه جذر یا توان دو دیتا و …<br /></li>
  <li>استانداردسازی دیتا. بعضی مدل ها زمانی بهتر کار می کنند که تمام ویژگی هاشون در یک مقیاس (scale) باشه.</li>
</ul>

<p>برای نمونه دیگری از تبدیل به مثال زیر دقت کنید:<br />
تصویر سمت چپ یک نمونه دیتاست رو نشون می ده که داده ها پراکنده هستند و نمی شه ارتباط درستی پیدا کرد. در همچین مواردی که یک دنباله طولانی داریم از لگاریتم استفاده می کنیم.</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/4-FeatureEngineering/FE_transformation.PNG?token=AEGZAVWA2CDPI5ZWFAG3HVTA6V6WA" /></div>

<p>در حالت کلی برای ایجاد ویژگی باید مسئله رو به درستی درک کنیم و دید خوبی نسبت بهش پیدا کنیم، و همچنین باید خلاقیت داشته باشیم و تو ذهنمون تصور کنیم که از چی می خوایم به چی برسیم و برای رسیدن به اون هدف چه ویژگی هایی نیاز داریم. مثلا در تشخیص پیام اسپم و غیراسپم پیدا کردن تعداد حروف a در پیام ها ممکنه کمک چندانی به حل مسئله نکنه و ویژگی مناسبی برای این مسئله نباشه ولی مثلا تعداد علائم نگارشی استفاده شده یا طول پیام به نظر مفیدتر می آد.</p>

<h2 id="تولید-ویژگی">تولید ویژگی</h2>

<p>بریم سراغ کد: <br />
اینجا می خوایم دو تا ویژگی طول پیام و درصد علائم نگارشی در پیام رو ایجاد کنیم.</p>

<p>بعد از خوندن دیتای خام می آییم ویژگی طول پیام رو اول می سازیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>datsset['body_len'] = dataset['body'].apply(lambda x: len(x) - x.count(" "))
</code></pre></div></div>

<p>خب <code class="language-plaintext highlighter-rouge">len(x)</code> به ما طول پیام رو می ده ولی نکته ای که هست اینه که کاراکتر فاصله هم شمرده می شه. مثلا ممکنه یک پیام به طول 10، نه کاراکتر فاصله داشته باشه و این نباید برابر باشه با پیامی که ده کاراکتر غیرفاصله داره. پس برای همین تعداد فاصله ها شمرده می شه و از طول کل پیام کم می شه.</p>

<p>یک ویژگی مفید دیگه هم درصد علائم نگارشی در پیام هاست. برای محاسبه ش باید یک تابع بنویسیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def count_punctuation(text):
    count = sum([1 for char in text if char in string.punctuation])
    return round(count/(len(char) - char.count(" ")), 3) * 100
</code></pre></div></div>

<p>این تابع چیکار می کنه؟ اول از همه یکی یکی علائم نگارشی رو می شماره و در نهایت با تابع <code class="language-plaintext highlighter-rouge">sum()</code> این یک ها رو جمع می کنیم. قراره درصد علائم نگارشی استفاده شده در پیام رو برگردونه. مقدار <code class="language-plaintext highlighter-rouge">count</code> تعداد علائم نگارشی یک پیامه. برای محاسبه درصد باید بیاییم این مقدار رو تقسیم بر کل کاراکترهای غیرفاصله پیام کنیم. بعد چون یک مقدار اعشاری برمی گردونه برای اینکه عدد خیلی طولانی نباشه رند می کنیم عدد رو تا سه رقم اعشار نشون بده و در نهایت در 100 ضرب می کنیم تا از حالت اعشار خارج شه.</p>

<p>کد کامل رو <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/4-FeatureEngineering/FeatureCreation.ipynb">اینجا</a> می تونید مشاهده کنید.</p>

<h2 id="ارزیابی-ویژگی">ارزیابی ویژگی</h2>

<p>حالا باید بررسی کنیم که این ویژگی ها برای این دیتاست مناسبن یا نه؟ که آیا می تونیم برای استخراج اطلاعات بهتر ازشون استفاده کنیم یا نه؟ از کتابخونه matplotlib برای رسم نمودار و هیستوگرام استفاده می کنیم. از تابع <code class="language-plaintext highlighter-rouge">hist()</code> در مجموعه توابع <code class="language-plaintext highlighter-rouge">pyplot</code> استفاده می کنیم:</p>

<p>ویژگی اولی که ساختیم طول پیام بود. حدس زدیم که احتمالا پیام های اسپم طولانی ترند. بریم ببینیم این حدس درسته یا نه؟</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(0, 200, 40)
pyplot.hist(dataset[dataset['label'] == 'spam']['body_len'], bins, alpha=0.5, density=True, label='spam')
</code></pre></div></div>

<p>محدوده و تعداد استوانه ها رو با <code class="language-plaintext highlighter-rouge">bin</code> مشخص می کنیم و مقادیری که می بینید به این ترتیبه: <code class="language-plaintext highlighter-rouge">bins = np.linspace(min_boundary, max_boundary, n_bins)</code>.<br />
ممکنه در کدهای قدیمی تر پارامتر <code class="language-plaintext highlighter-rouge">normed=True</code> رو ببینید که این معادل پارامتر <code class="language-plaintext highlighter-rouge">density</code> است که اینجا استفاده کردیم در نسخه های جدیدتر پایتون از این پارامتر استفاده می شه.</p>

<p>همین خط کد رو باید یرای پیام های غیراسپم هم بنویسیم تا بتونیم مقایسه کنیم.<br />
بعد از گرفتن خروجی می بینیم که پیش بینی مون درست بوده و پیام های اسپم بسیار طولانی تر از پیام های غیراسپمن. پس این ویژگی که ایجاد کردیم مناسب و مفیده.</p>

<p>برای تست ویژگی بعدی همین خط کد رو داریم فقط به جای <code class="language-plaintext highlighter-rouge">[body_len]</code> باید <code class="language-plaintext highlighter-rouge">[punct%]</code> رو بذاریم تا ببینیم طبق حدسمون پیام های اسپم بیشتر از غیراسپما علائم نگارشی دارند؟</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(0, 50, 40)
pyplot.hist(dataset[dataset['label'] == 'spam']['punct%'], bins, alpha=0.5, density=True, label='spam')
</code></pre></div></div>

<p>و بعد از اجرای کد می بینیم که تفاوت چشمگیری در استفاده از علائم نگارشی بین پیام های اسپم و غیراسپم وجود نداره. و همونطور که در این توزیع دیده می شه یه دنباله ای در پیام های غیراسپم ایجاد شده که احتمالا باید از تبدیل (transformation) استفاده کنیم تا بهتر بتونیم تصمیم بگیریم.</p>

<p><a href="https://github.com/spacelover1/NLP-with-Python/blob/main/4-FeatureEngineering/FeatureCreation%26Evaluation.ipynb">کد کامل این بخش</a>.</p>

<h2 id="تبدیل-transformation">تبدیل (Transformation)</h2>

<p>در این بخش می خوایم بررسی کنیم که دو تا ویژگی ای که ایجاد کردیم نیاز به تبدیل دارند یا نه.<br />
اولین کاری که باید انجام بدیم اینه که توزیع کاملشون رو رسم کنیم و بعد طبق اون تصمیم بگیریم. مواردی که نشون می ده تبدیل نیازه یا نه، عدم تقارن شدید، دنباله طولانی و outlierها (یعنی اون نقاطی که خیلی از توزیع اصلی دورافتادن).</p>

<h3 id="طول-پیام">طول پیام</h3>

<p>برای شروع <code class="language-plaintext highlighter-rouge">bins</code> رو مثل قبل تعریف می کنیم، از صفر شروع شه تا 200 بره و 40 تا bin تولید شه:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(0, 200, 40)
pyplot.hist(dataset['body_len'], bins)
</code></pre></div></div>

<p>نیازی به پارامترای دیگه نیست چون می خوایم توزیع کلی طول پیام ها رو ببینیم، بدون توجه به لیبلشون.</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/4-FeatureEngineering/length_distribution.PNG" alt="length distribution" /></div>

<p>همونطور که قبلا دیدیم طول پیام های اسپم بیشتر از غیراسپم ها بود پس این توزیع درست و با معنیه. پس این ویژگی نیازی به تبدیل نداره.</p>

<h3 id="درصد-پیام-های-نگارشی">درصد پیام های نگارشی</h3>

<p>برای بررسی ویژگی بعد 200 رو به 50 تغییر می دیم یعنی متن های تا 50 تا علائم نگارشی رو بررسی کنه.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bins = np.linspace(0, 50, 40)
pyplot.hist(dataset['punct%'], bins)
</code></pre></div></div>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/4-FeatureEngineering/punct_percentage.PNG" alt="punctuation percentage" /></div>

<p>این توزیع رو همونطور که می بینید تقارن نداره مقدار زیادی از دیتا نزدیک صفر جمع شده و همینطور یک دنباله طول و دراز هم تشکیل شده که نشون می ده نیاز به تبدیل داره.</p>

<p>حالا که ویژگی هایی که نیاز به تبدیل دارند رو مشخص کردیم، باید تبدیل رو شروع کنیم.</p>

<p>تبدیل (Transformation) فرایندیه که هر داده رو در یک ستون مشخص به صورت سیستماتیک تغییر می ده (مثلا محاسبه جذر یا توان دوم هر داده) تا دیتا رو برای استفاده بهتر مدل از اون، پاکسازی کنه.</p>

<p>مجموعه تبدیلی که اینجا استفاده می کنیم بسیار رایجه و Box-Cox Power Transformations نام داره. فرم پایه این تبدیلات y به توان x است. جدول زیر این تبدیل رو برای بازه <code class="language-plaintext highlighter-rouge">[-2,2]</code> نمایش می ده:</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/4-FeatureEngineering/cox-box-transformation.PNG" alt="cox-box transformation" /></div>

<p>حالا اگر فرض کنیم 50 درصد یک متن علائم نگارشیه، در جدول بالا <code class="language-plaintext highlighter-rouge">x = 50</code> می شه.</p>

<h3 id="فرایند-تبدیل">فرایند تبدیل</h3>

<p>1- مشخص کردن بازه توانی <br />
2- اعمال هر تبدیل را به هر مقدار ویژگی انتخاب شده<br />
3- استفاده از معیارهایی برای تشخیص تبدیلی که بهترین توزیع را تولید می کند</p>

<p>بعد از بررسی ویژگی هایی که ایجاد کردیم دیدیم که ویژگی علائم نگارشی نیاز به تبدیل داره. کد اعمال تبدیل رو به این صورت می نویسیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for i in range(1, 6):
    pyplot.hist((dataset['punct%'])** (1/i), bins=40)
    pyplot.title('transformation: 1/{}'.format(str(i)))
</code></pre></div></div>

<p><a href="https://github.com/spacelover1/NLP-with-Python/blob/main/4-FeatureEngineering/featureEngineering_transformation.ipynb">کد کامل این بخش</a></p>

<p>برای مطالعه بیشتر درباره تبدیل و مهندسی ویژگی <a href="https://towardsdatascience.com/data-transformation-and-feature-engineering-e3c7dfbb4899">این مقاله</a> رو می تونید مطالعه کنید.</p>

<p><a href="https://github.com/spacelover1/personalBlog/blob/master/ZeinabSalimi-cv.pdf">فایل</a></p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>مبانی پردازش زبان طبیعی(NLP)- سه</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/nlp-basics-three.html"/>
    <id>urn:uuid:</id>
    <updated>2021-07-15T00:00:00Z</updated>
    <category term="nlp"/><category term="اموزش"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p>در این قسمت در مورد برداری کردن دیتا صحبت می کنیم. <br />
تا اینجا دیتا رو خوندیم و تا حدودی نرمالیزه کردیم. الان پایتون دیتا رو فقط یک سری رشته کاراکتر می بینه. حالا برای اینکه مدل ماشین لرنینگ و پایتون این دیتا رو درک کنه باید دیتا برداری بشه. برداری کردن یعنی چی؟ یعنی متن به عددصحیح تبدیل شه و یک بردار ویژگی ساخته شه.<br />
حالا بردار ویژگی در اینجا یعنی متن هر پیام رو بگیریم و به یک بردارعددی تبدیل کنیم که نمایش دهنده متن اون پیام باشه. <br />
چطوری این کار رو انجام می دیم؟ در ادامه درباره این مورد صحبت می کنیم.<br />
چندین روش برای برداری کردن ویژگی ها وجود داره که در ادامه سه روش رایج رو بررسی می کنیم.</p>

<h2 id="روش-اول-بردار-تعداد-count-vectorization"><strong>روش اول: بردار تعداد (Count Vectorization)</strong></h2>

<p>در این روش هر پیام گرفته می شه و هر کلمه به عنوان یک ویژگی در نظر گرفته می شه و بعد تعداد تکرار هر کلمه در اون پیام ثبت می شه. در نهایت یک ماتریسی داریم که هر سطر مربوط به یک پیام و هر ستون نمایش دهنده یک کلمه است. و در نهایت پایتون با بررسی این ماتریس یک ارتباطی بین کلمات موجود در پیام و لیبل اون پیام پیدا می کنه تا در آینده که بهش پیام های بدون لیبل بدیم بتونه به درسی برچسب گذاری کنه.</p>

<p>برای درک بهتر این فرایند به عکس زیر دقت کنید:</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/3-VectorizingRawData/vectorization_example.PNG" alt="vectorization_example" /></div>

<p>دراین تصویر فقط دو رشته offer و lol از لیست کلمات پیام ها انتخاب شده و تعداد تکرارشون محاسبه شده. همونطور که در جدول سمت چپ و راست می بینید پیام هایی که برچسب غیر اسپم دارند در آن ها رشته lol وجود داشته و تکرار شده ولی شامل رشته offer نیستند و برعکس پیام های اسپم اکثرا رشته offer رو شامل می شن. <br />
این یک مثال بسیار ساده برای درک فرایند و مفهوم بردار تعداد است.</p>

<p>حالا در عمل این روش رو پیاده می کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd
import re
import string
import nltk

pd.set_option('display.max_colwidth', 100)
dataset = pd.read_csv('SMSSpamCollection.tsv', sep='\t')
dataset.columns = ['label', 'body']

nltk.download('stopwords')
stopwords = nltk.corpus.stopwords.words('english')
ps = nltk.PorterStemmer()


def clean_text(text):
  text = "".join([word.lower() for word in text if word not in string.punctuation])
  tokens = re.split('\W+', text)
  text = [ps.stem(word) for word in tokens if word not in stopwords]
  return text
</code></pre></div></div>

<p>بعد از خوندن و پاکسازی دیتا، سراغ برداری کردن می ریم.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.feature_extraction import CountVectorizer

count_vect = CountVectorizer(analyzer=func_name)
X_counts = count_vect.fit_transform(dataset['body'])
</code></pre></div></div>

<p>حالا می تونیم با استفاده از <code class="language-plaintext highlighter-rouge">X_counts.shape</code> تعداد پیام ها و تعداد رشته های منحصر بفرد در این پیام ها رو ببینیم. در این دیتاست 5567 پیام و 8104 رشته منحصر بفرد داریم که همون ویژگی های ما هستند. این اعداد تعداد سطرو و ستون های ماتریس رو نمایش می ده.<br />
و <code class="language-plaintext highlighter-rouge">count_vect.get_feature_names()</code> رشته های منحصربفرد رو نمایش می ده.</p>

<p>تابع هایپرپارامترهای دیگه ای هم داره که <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">اینجا</a> می تونید دربارشون بخونید.</p>

<p>حالا در اینجا برای یادگیری 20 پیام اول رو  برداری می کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sample = dataset[0:20]
count_vect_sample = CountVectorizer(analyzer=clean_text)
X_counts_sample = count_vect_sample.fit_transform(dataset['body'])
</code></pre></div></div>

<p>و الان وقتی سایز دیتای نمونه رو ببینیم 192 رشته منحصربفرد داریم. خروجی و کد کامل این بخش رو <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/3-VectorizingRawData/CountVectorization.ipynb">اینجا</a> می تونید ببینید.</p>

<h2 id="روش-دوم-بردار-n-grams-n-gram-vectorizing"><strong>روش دوم: بردار N-Grams (N-gram vectorizing)</strong></h2>

<p>این روش هم تا حدود زیادی مشابه روش قبلیه و ساختار کدش مشابه اونه. در اینجا هم هر سطر پیام ها هستند ولی هر ستون به جای نمایش یک رشته، ترکیب nتایی از رشته هاست. برای درک بهتر تصویر زیر  رو ببینید:</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/3-VectorizingRawData/ngrams.png?token=AEGZAVTZYIIT2UNASADUQN3A6KJCE" alt="ngrams" /></div>

<p>مثل مرحله قبل دیتا رو می خونیم و بعد باید تابعی بنویسیم که مراحل پاکسازی رو انجام بده. بخش قبل یک لیستی از توکن رو می دادیم به vectorizer اما الان چون می خواد ترکیبی از کلمه ها رو بسازه باید ورودی بهش یک رشته بدیم. پس در آخر باید توکن ها رو مثل یک جمله کنار هم دیگه قرار بدیم و این کار رو با تابع <code class="language-plaintext highlighter-rouge">join()</code> انجام می دیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def clean_text(text):
  text = "".join([word.lower() for word in text if word not in string.punctuation])
  tokens = re.split('\W+', text)
  text = " ".join([ps.stem(word) for word in tokens if word not in stopwords])
  return text
</code></pre></div></div>

<p>اگر یادتون باشه خط اول کاراکترها رو یکی یکی بررسی می کرد برای پیدا کردن علائم نگارشی و در اخر با <code class="language-plaintext highlighter-rouge">join()</code> این کاراکترها رو بهم متصل کردیم. در <code class="language-plaintext highlighter-rouge">join()</code> دومی قرار کلمه ها کنار هم بیان تا جمله بسازن پس باید یک فاصله بین هر کلمه باشه.</p>

<p>در اینجا هم از CountVectorizer استفاده می کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ngram_vect = CountVectorizer(ngram_range=(2,2))
X_counts = ngram_vect.fit_transform(dataset['cleaned_text'])
</code></pre></div></div>

<p>در <code class="language-plaintext highlighter-rouge">ngram_range</code> مشخص می کنیم که ترکیب چندتایی از کلمه ها بسازه. مثلا (1,3) یعنی همه ترکیبهای یکی، دوتایی و سه تایی. <br />
همونطور که مشاهده می کنید تعداد فیچرها اینجا خیلی زیاد می شه. نکته ای که باید توجه کنیم اینه که چه زمانی از هر کدوم از این روش ها استفاده کنیم. با توجه به مسئله ممکنه یکی از این روش ها نتیجه بهتری بده. لزوما نمی شه گفت یکی از این روش ها بهتر از دیگری است.</p>

<p>کدهای این بخش در <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/3-VectorizingRawData/NGrams.ipynb">اینجا</a> قابل مشاهده است.</p>

<h2 id="روش-سوم-te-idf-term-frequency--inverse-document-frequenct"><strong>روش سوم: TE-IDF (Term Frequency- Inverse Document Frequenct)</strong></h2>

<p>در این روش هم یک ماتریس ایجاد می شه که سطرها پیام ها هستند و هر ستون یک کلمه رو مشخص می کنه. اما سلول های این ماتریس دیگه تعداد تکرار کلمه رو نشون نمی ده بلکه وزن اون کلمه رو نشون می ده، تا اهمیت هر کلمه رو در اون پیام مشخص کنه. <br />
فرمول زیر برای محاسبه این وزنه:</p>

<div style="text-align:center"><img src="https://raw.githubusercontent.com/spacelover1/NLP-with-Python/main/3-VectorizingRawData/tf-idf.PNG?token=AEGZAVSASZLPTSDT75HLYL3A6PNMY" alt="tf-idf_formula" /></div>

<p>بریم ببینیم هر کدوم از این عبارات در فرمول چیو مشخص می کنه و چطوری محاسبه می شه:</p>

<p>عبارت tf تعداد تکرار یک کلمه در یک جمله تقسیم بر تعداد کل کلمات اون جمله. <br />
مثلا در جمله “امروز هوا گرم است” اگر کلمه “گرم” رو در نظر بگیریم، مقدار tf می شه: 1/4 یا 0.25</p>

<p>قسمت دوم این فرمول مشخص می کنه که هر کلمه چند بار تو کل جملات (پیام ها) تکرار شده.
در همین مثال اگر متن ما شامل 20 جمله باشه و کلمه گرم فقط یک بار تکرار شده باشه، نتیجه می شه:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>N = 20, df = 1 &gt;&gt;&gt;&gt; log(N/df) = log(20/1) = 1.301
</code></pre></div></div>

<p>مبنای لگاریتم هم 10 است.</p>

<p>و درنهایت:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.25 * 1.301 = 0.325
</code></pre></div></div>

<p>هر چقدر مقدار داخل لگاریتم بزرگتر باشه، لگاریتم اون مقدارم بزرگتر می شه. مثلا فرض کنید تعداد کل جملات 40 باشه مقدار لگاریتم می شه 1.6 یعنی بیشتر از مقدار قبل. پس طبق این فرمول هر چقدر یک کلمه در متن کمتر تکرار شده باشه، عددی که تولید می شه بزرگتره. <br />
و اگر یک کلمه در یک جمله خیلی تکرار شده باشه ولی در کل متن خیلی کم باشه، مقدار نهایی عدد بزرگی می شه.<br />
به طور خلاصه این روش کمک می کنه کلمات مهم ولی نادر رو در متن پیدا کنید.</p>

<p>مثل روش های قبل دیتا رو می خونیم و یک تابع برای پاکسازی دیتا می نویسیم. این تابع رو مثل روش اول می نویسیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def clean_text(text):
  text = "".join([word.lower() for word in text if word not in string.punctuation])
  tokens = re.split('\W+', text)
  text = [ps.stem(word) for word in tokens if word not in stopwords]
  return text
</code></pre></div></div>

<p>و سپس وکتورایز tf-idf رو می سازیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vect = TfidfVectorizer(analyzer=clean_text)
X_tfidf = tfidf_vect.fit_transform(dataset['body'])
</code></pre></div></div>

<p>برای اینکه یه دیدی بگیریم بهتره یه بخشش کوچکی از دیتا رو انتخاب کنیم و دیتافریم ماتریس رو بسازیم تا خروجی رو ببینیم. برای ایجاد ماتریس از تابع <code class="language-plaintext highlighter-rouge">toarray()</code> و دیتافریم پانداس استفاده می کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X_tfidf_df = pd.DataFrame(X_tfidf_sample.toarray())
</code></pre></div></div>

<p>کد کامل <a href="Uhttps://github.com/spacelover1/NLP-with-Python/blob/main/3-VectorizingRawData/TF_IDF.ipynbRL">اینجا</a> قرار داره.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>مبانی پردازش زبان طبیعی(NLP)- دو</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/nlp-basics-two.html"/>
    <id>urn:uuid:</id>
    <updated>2021-07-14T00:00:00Z</updated>
    <category term="nlp"/><category term="اموزش"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p>در قسمت قبل فایل متنی رو به دو روش آسان و دشوار خوندیم. و پاکسازی دیتا رو توسط سه متد پیش پردازش یاد گرفتیم: حذف علائم نگارشی، توکنایز کردن (جداسازی کلمات)، حذف کلمات بدون معنی. و گفتیم که یک مرحله چهارمی هم برای پاکسازی یا نرمالسازی داده متنی می شه استفاده کرد که شاید همیشه به اندازه مراحل قبل اهمیت نداشته باشه. در این قسمت درباره این مرحله چهارم صحبت می کنیم.</p>

<h2 id="بخش-پنجم-stemming"><strong>بخش پنجم: Stemming</strong></h2>

<p>کاری که stemming انجام می ده اینه که میاد پسوند و پیشوند رو از کلمه حذف می کنه و هر چی باقی موند رو به عنوان خروجی میده، پس ممکنه خروجی حتی کلمه نباشه. خب پس چرا ازش استفاده می کنیم؟ بخاطر سادگی و سرعتی که داره.</p>

<p>اول از همه روی یک سری کلمات این روش رو اجرا می کنیم تا بیشتر باهاش آشنا شیم و بعد روی دیتاستی که در قسمت قبل بررسی کردیم. <br />
باید اول کتابخونه <code class="language-plaintext highlighter-rouge">nltk</code> رو ایمپورت کنیم. سپس از  استمر <code class="language-plaintext highlighter-rouge">PorterStemmer()</code>  استفاده می کنیم. این استمرها برای هر زبانی متفاوته، برای زبان انگلیسی دو استمر <code class="language-plaintext highlighter-rouge">PorterStammer</code> و <code class="language-plaintext highlighter-rouge">LancasterStammer</code> وجود داره. اولی رایجتره و سریعتر.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import nltk
ps = nltk.PorterStemmer()
</code></pre></div></div>

<p>با استفاده از <code class="language-plaintext highlighter-rouge">dir(ps)</code> توابعی که این استمر داره رو می تونیم مشاهده کنیم. تابع <code class="language-plaintext highlighter-rouge">stem</code> بیشتر استفاده می شه.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(ps.stem('grow'))
print(ps.stem('growing'))
print(ps.stem('grows'))
</code></pre></div></div>

<p>همه این کلمات رو خلاصه می کنه به grow. در مثال بعدی فرق فعل و فاعل رو می دونه.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(ps.stem('runs'))  
print(ps.stem('running'))
print(ps.stem('runner'))
</code></pre></div></div>

<p>حالا بریم سراغ دیتاست پیام های اسپم و غیر اسپم.<br />
ابتدا دیتا رو می خونیم:
    import pandas as pd
    import re
    import string</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nltk.download('stopwords')
stopword = nltk.corpus.stopwords.words('english')
pd.set_option('display.max_colwidth', 100)

dataset = pd.read_csv('SMSSpamCollection.tsv', sep='\t', header=None)
dataset.columns = ('label', 'body')
dataset.head()
</code></pre></div></div>

<p>کتابخونه های مورد نیاز رو هم من همین ابتدا ایمپورت کردم. سپس سه مرحله پاکسازی دیتا رو انجام  می دیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def clean_data(text):
    text = [word for word in text if word not in string.punctuation]
    tokens = re.split('\W+', text)
    text = [word for word in tokens if word not in stopword]
    return text

dataset['tokenized_text'] = dataset['body'].apply(lambda x: clean_data(x))



def stemming(tokenized_text):
    text = [ps.stem(word) for word in tokenized_text]
    return text

dataset['stemmed_text'] = dataset['tokenized_text'].apply(lambda x: stemming(x))
</code></pre></div></div>

<h2 id="بخش-ششم-lemmatization"><strong>بخش ششم: Lemmatization</strong></h2>

<p>همونطور که دیدیم خروجی <code class="language-plaintext highlighter-rouge">stemming</code> لزوما کلمه نیست و ممکنه یک چیز بی معنی باشه یا حتی اشتباه. یک متد دیگه <code class="language-plaintext highlighter-rouge">Lemmatization</code> نام داره که خروجی این روش حتما کلمه ای در دیکشنریه. یعنی معمولا کلمات رو می بره به ریشه شون.</p>

<p>به مثال های زیر توجه کنید.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(ps.stem('meaning')) ==&gt; mean
print(ps.stem('meanness')) ==&gt; mean

print(wn.lemmatize('meaning')) ==&gt; meaning
print(wn.lemmatize('meanness')) ==&gt; meanness


print(ps.stem('goose')) ==&gt; goos
print(ps.stem('geese')) ==&gt; gees

print(wn.lemmatize('goose')) ==&gt; goose
print(wn.lemmatize('geese')) ==&gt; goose
</code></pre></div></div>

<p>در واقع stemming رویکرد الگوریتمی داره و فقط با رشته ای که بهش می دیم کار می کنه و فقط پسوند رو حذف می کنه.<br />
اما lemmatization پیچیده تره و کلمه ای که بهش داده می شه رو در لیست لغات بررسی می کنه و پرداش می کنه و بعد ریشه کلمه رو بر می گردونه مشکلش اینه که اگر کلمه ای که بهش داده شده در لیست لغات نباشه همونو برمی گردونه.</p>

<p>همین اتفاقی که در این مثال ها افتاده، که همونطور که می بینیم خلاصه نکردن بهتر از رشته کلمه اشتباه برگردوندنه.</p>

<p>حالا می خوایم تکنیک lemmatization رو روی دیتاست پیام ها پیاده کنیم. مثل قبل، ابتدا دیتا رو می خونیم و پاکسازی های اولیه رو انجام می دیم و بعد از lemmatizer استفاده می کنیم. <br />
در اینجا من فقط تابع lemmatizer رو نوشتم. کد کامل رو <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/2-SupplementalDataCleaning/UsingaLemmatizer.ipynb">اینجا</a> می تونید مشاهده کنید.</p>

<p>برای درک بهتر این دو روش می تونید <a href="https://www.datacamp.com/community/tutorials/stemming-lemmatization-python">این توضیح انگلیسی</a> رو مطالعه کنید.</p>

</div>]]>
    </content>
  </entry>

  <entry>
    <title>مبانی پردازش زبان طبیعی(NLP)- یک</title>
    <link rel="alternate" type="text/html" href="https://spacelover.ir/nlp-basics-one.html"/>
    <id>urn:uuid:</id>
    <updated>2021-07-10T00:00:00Z</updated>
    <category term="nlp"/><category term="اموزش"/>
    <content type="html">
      <![CDATA[<div dir="rtl"><p>این پست رو با یک نقل قول شروع می کنم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Motivation often comes after starting, not before. Action produces momentum."
</code></pre></div></div>

<p>تعاریف متفاوتی برای پردازش زبان طبیعی وجود داره ولی شاید کامل ترینش این باشه:</p>

<blockquote>
  <p>پردازش زبان طبیعی شاخه ای از دانشه که بر روی توانایی کامپیوتر برای درک، تحلیل، تغییر و احتمالا تولید زبان انسان متمرکز است.</p>
</blockquote>

<p>در چند سری پست آینده می خوام یک سری مبانی برنامه نویسی مربوط به پردازش زبان طبیعی رو توضیح بدم، کدها هم در <a href="https://github.com/spacelover1/NLP-with-Python"><u>این ریپو</u></a> قرار دارند. در این آموزش فرض شده که شما با مبانی پایتون یا حداقل برنامه نویسی آشنا هستید چون اینجا مبانی، مثل استفاده از لیست و دیگر نوع داده ها آموزش داده نمی شه.</p>

<p>زبانی که در این سری استفاده می شه پایتونه، پس نیازه که پایتون رو نصب کنید. برای محیط برنامه نویسی هم می تونید از <a href="https://www.jetbrains.com/pycharm/download/#section=windows"><u>پایچارم</u></a> یا ژوپیتر استفاده کنید. برای استفاده از ژوپیتر باید <a href="https://docs.anaconda.com/anaconda/"><u>آناکوندا</u></a> رو نصب کنید. لینک سایت اصلی این برنامه ها رو هم قرار دادم که برای دانلود می تونید استفاده کنید. حتما دقت کنید که هر برنامه رو برای سیستم عامل خودتون دانلود کنید (خود این سایت ها به صورت خودکار سیستم عامل رو شناسایی می کنند).</p>

<h2 id="بخش-اول-خواندن-فایل"><strong>بخش اول: خواندن فایل</strong></h2>

<p>خب شروع کنیم. تو این قسمت قراره یک فایل متنی رو بخونیم و یک سری مرتب سازی ها روش انجام بدیم. اول یک با دیتاست بازی می کنیم تا  یکسری اطلاعات از دیتاست دستمون بیاد و بعد یک روش ساده برای خوندن این دیتاست معرفی می کنیم. <br /> 
فایلی که استفاده می شه در ریپویی که لینکش رو بالا گذاشتم موجوده. برای خوندن فایل باید اول با استفاده از تابع <code class="language-plaintext highlighter-rouge">open()</code> فایل رو باز کنیم و با تابع <code class="language-plaintext highlighter-rouge">read()</code> فایل باز شده رو می خونیم و محتواش رو در یک متغیر به اسم <code class="language-plaintext highlighter-rouge">raw_data</code> می نویسیم.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>raw_data = open('file_name').read()
</code></pre></div></div>

<p>خب حالا باید ببینیم محتوای این <code class="language-plaintext highlighter-rouge">raw_data</code> به چه صورته تا ببینیم نیاز به مرتب سازی داره برای پردازش های بعدی یا نه. فایل رو اگر دیده باشید داده نه ساختاریافته نیست و خیلی هم بدون ساختار نیست، اول هر خط کلمه ham یا spam داره و بعد با یه تب فاصله یک متنی جلوش نوشته شده. بریم چند خط از فایل رو ببینیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>raw_data[0:500]
</code></pre></div></div>

<p>بعد از اجرای این خط 500 کاراکتر اول فایل نمایش داده می شه. همون طور که می بینید محتوای فایل یک سری رشته است که کاراکترهایی مثل <code class="language-plaintext highlighter-rouge">\t</code> و <code class="language-plaintext highlighter-rouge">\n</code> داره. اولی فاصلی ای مه باتب ایجاد شده رو نشون می ده و دومی باعث می شه بره خط بعدی.
خب ما الان می خوایم یکم داده رو مرتب کنیم، برای پردازش های بعدی. برای اینکار کاراکتر <code class="language-plaintext highlighter-rouge">\t</code> رو با <code class="language-plaintext highlighter-rouge">\n</code> جایگزین می کنیم و بعد با تابع <code class="language-plaintext highlighter-rouge">split</code> این رشته رو به لیست تبدیل می کنیم.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>parsed_data = raw_data.replace('\t','\n').split('\n')
</code></pre></div></div>

<p>بریم ببینیم لیست مون چه شکلیه:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>parsed_data[:5]
</code></pre></div></div>

<p>الان برچسب یا لیبل در خونه های با ایندکس زوج قرار داره و متن پیام در خونه های ایندکس فرد. حالا که یه نظمی تو ساختار ایجاد شده بریم هر کدوم رو تو لیست جدا بنویسیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>label_list  = parsed_data[0::2]
text_list = parsed_data[1::2]
</code></pre></div></div>

<p>اولی لیست رو از خونه صفر می خونه و یکی درمیون مقادیر رو می ریزه تو لیست لیبلا، یعنی همون خونه های زوج. خط دوم از خونه یک میاد یکی در میون می خونه و باعث می شه خونه های فرد رو بخونه.<br />
می تونیم این دو لیست رو ببینیم و مطمئن شیم همونطور که می خواستیم شده. اینجا از تابع <code class="language-plaintext highlighter-rouge">print()</code> استفاده می کنیم چون در غیر اینصورت ژوپیتر فقط خروجی اخرین خط رو می ده.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(label_list[:5])
print(text_list[:5])
</code></pre></div></div>

<p>حالا باید این دو لیست رو یه جوری با هم ترکیب کنیم تا برای تحلیل های بعدی بتونیم ازشون استفاده کنیم. برای این کار از تابع <code class="language-plaintext highlighter-rouge">DataFrame()</code> پانداس استفاده می کنیم و در این دیتافریم یک دیکشنری می سازیم. بعد از ایمپورت کتابخونه می تونیم از توابعش استفاده کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd
full_corpus = DataFrame({'label': label_list, 'body': text_list})
</code></pre></div></div>

<p>احتمالا بعد از اجرای این خط کد اروری مشاهده می کنید که می گه ارایه ها باید طولشون یکسان باشه. بریم طول این دو لیست رو چک کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print(len(label_list))
print(len(text_list))
</code></pre></div></div>

<p>همون طور که می بینید طول لیست لیبل یه دونه بیشتر از متنه. بریم چند تا خونه اخر هر دو لیست رو ببینیم چه خبره:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>label_list [-5:]
text_list[-5:]
</code></pre></div></div>

<p>خونه اخر لیست لیبلا یه خونه خالیه. پس وقتی این لیست رو می خونیم، خونه اخر رو باید نادیده بگیریم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>full_corpus = DataFrame({'label': label_list[:-1], 'body': text_list})
</code></pre></div></div>

<p>ببینیم دیتافریم مون چه شکلیه:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>full_corpus.head()
</code></pre></div></div>

<p>خب الان دیتامون یکم ساختار پیدا کرده و نسبت به اول خوانایی بهتری داره. <br /></p>

<p>و اما روش ساده خوندن این دیتاست. همون اول که نگاهی به داده انداختیم و <code class="language-plaintext highlighter-rouge">\t</code> رو دیدیم باید متوجه شیم که این یک فایلیه که عناصرش با تب از هم جدا شدن. برای خوندن این فایل ها می تونیم از تابع <code class="language-plaintext highlighter-rouge">read_csv</code> استفاده کنیم، مقدار هدر رو هم در اینجا <code class="language-plaintext highlighter-rouge">None</code> قرار می دیم چون در فایل اصلی ردیفی برای عنوان ستون وجود نداره.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dataset = read_csv('file_name', sep="\t", header=None)
</code></pre></div></div>

<p>برای مشاهده هم می تونیم از تابع <code class="language-plaintext highlighter-rouge">head()</code> استفاده کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dataset.head()
</code></pre></div></div>

<p>همونطور که می بینید دیگه ردیف اولی برای عنوان ستون ها وجود نداره.</p>

<p>در این بخش یاد گرفتیم که یک دیتاست متنی رو چطوری بخونیم و برای تحلیل های بعدی مرتبش کنیم.
کدهای بخش اول رو از <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/1-Basics/01-read_file.ipynb"><u>اینجا</u></a> می تونید ببینید.</p>

<h2 id="بخش-دوم-بررسی-دیتاست"><strong>بخش دوم: بررسی دیتاست</strong></h2>

<p>بخش قبل یاد گرفتیم که چطور دیتا رو به روش پیچیده بخونیم تا با یک سری از ابزارهای تغییر در متن آشنا شیم و در آخر روش ساده رو یاد گرفتیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dataset = read_csv('file_name', sep="\t", header=None)
</code></pre></div></div>

<p>حالا برای ستون ها اسم برچسب می ذاریم تا راحت بتونیم دیتا رو بررسی کنیم:
    dataset.columns[‘label’, ‘body’]</p>

<p>اول از همه بریم سایز دیتاست رو دربیاریم، ببینیم چند تا سطر و ستون داره:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print("There are {} rows and {} columns.".format(len(dataset), len(dataset.columns)))
</code></pre></div></div>

<p>حالا باید تعداد سطرهای اسپم و غیر اسپم رو دربیاریم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print("Out of {} rows, {} rows are spam and {} rows are ham.".format(
                                                                    len(dataset),
                                                                    len(dataset[dataset['label'] == 'spam']),
                                                                    len(dataset[dataset['label'] == 'hame'])
                                                                    ))
</code></pre></div></div>

<p>ممکنه بعضی ردیفا هیچ لیبلی نداشته باشه، باید تعداد اون ها رو هم پیدا کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>print("Number of null in label: {}".format(dataset['label'].isnull().sum()))
print("Number of null in body: {}".format(dataset['body'].isnull().sum()))
</code></pre></div></div>

<p>خروجی تابع <code class="language-plaintext highlighter-rouge">isnull()</code> بولینه یعنی True یا False برمی گردونه. هر سطر رو بررسی می کنه اگر اون ستونی که داریم بررسی می کنیم تو اون سطر دیتا نداشته باشه True میشه و در غیراینصورت False. 
وقتی بعد از <code class="language-plaintext highlighter-rouge">isnull()</code> تابع <code class="language-plaintext highlighter-rouge">sum()</code> رو میاریم یعنی تعداد کل ریف هایی که لیبل ندارن رو بده.</p>

<p>کدهای بخش دوم رو از <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/1-Basics/02-Exploring%20Dataset.ipynb"><u>اینجا</u></a> می تونید ببینید.</p>

<h2 id="بخش-سوم-عبارات-منظم"><strong>بخش سوم: عبارات منظم</strong></h2>

<p>دلیل اصلی یاد گرفتن عبارات با قاعده اینه که بتونیم جمله رو tokenize کنیم یا به عبارتی کلمه های جمله رو از هم جدا کنیم که پایتون بدونه که دنبال چی بگرده. گاهی اوقات لازمه که یک الگوی خاصی از کاراکترها رو در یک رشته متن پیدا کنیم، این کار به راحتی با عبارات با قاعده قابل انجامه. البته خیلی راحتم نه :) چون روش هایی که برای تشخیص این الگوها وجود داره خیلی گسترده است ولی یک سری موارد کلی رو اگر یاد بگیرید و تمرین کنید براتون راحت می شه. از <a href="https://docs.python.org/3/library/re.html">داکیومنت عبارات با قاعده در پایتون</a> هم می تونید استفاده کنید.</p>

<p>در اینجا دو روش رو یاد می گیریم. برای تست این دو روش یک متن رو به سه حالت نوشتم و قراره که کلمه ها رو از هم جدا کنیم.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import re
text = "This is a made up string to test 2 different regex methods"
messy_text = "This            is a made up string to              test 2   different regex methods"
messy_text1 = "This-is-a''''made-up/string-+to*****test-2 &gt;&gt;&gt;&gt;&gt;&gt;-different.regex-methods"
</code></pre></div></div>

<p>برای اینکه بتونیم از این عبارات با قاعده در پایتون استفاده کنیم باید کتابخونه ش رو ایمپورت کنیم. <br />
کلمات جمله اول با فاصله از هم جدا شدند پس یه الگو به دست اومد، می تونیم هر جا کاراکتر فاصله بود تشخیص بدیم و کلمات رو از هم جدا کنیم. با استفاده از تابع <code class="language-plaintext highlighter-rouge">split()</code> و ‘\s’ به کوچک و بزرگ بودن حروف دقت کنید، چون هر کدوم معنی خاصی دارند. در اینجا حرف کوچک s یعنی از نقاطی که کاراکتر فاصله وجود داره کلمات رو جدا کن.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re.split('\s', 'text')
</code></pre></div></div>

<p>اگر همین کد رو روی متن دوم اجرا کنیم جوابی که می خوایم رو نمی گیریم، چون بیشتر از یک کاراکتر فاصله بین بعضی کلمات وجود داره. پس از ‘\s+’ استفاده می کنیم. این یعنی یک فاصله یا بیشتر اگر بین کلمات بود حذف کن.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re.split('\s+', 'messy_text')
</code></pre></div></div>

<p>برای متن سوم هیچ کدوم از راه حلای بالا جواب نمی ده. و باید از راه دیگه ای بریم. اینجا به غیر از کاراکتر فاصله، کاراکترهای دیگه ای هم وجود داره. پس می تونیم بیاییم بگیم هر کاراکتر غیر کلمه ای رو حذف کن. و علامت + رو هم می ذاریم چون کاراکترهای غیرکلمه بیشتر از یکبار تکرار شدن بین هر کلمه.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re.split('\W+', 'messy_text1')
</code></pre></div></div>

<p>کاری که تا الان انجام می دادیم این بود که بیاییم هر چی غیر از کلمه است رو جدا می کردیم تا کلمه ها جدا شن. یه راه دیگه برای جداسازی کلمات اینه که بیاییم مستقیم کلمه ها رو پیدا کنیم. برای این کار از تابع <code class="language-plaintext highlighter-rouge">findall()</code> استفاده می کنیم.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re.findall('\S+', text)
</code></pre></div></div>

<p>در کد بالا از حرف بزرگ S استفاده کردیم. گفتیم هر چی غیر کاراکتر فاصله. که این روش دوباره روی متن سوم جواب نمیده. که می تونیم از روش زیر به جای این استفاده کنیم.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re.findall('\w+', 'messy_text1')
</code></pre></div></div>

<p>حرف کوچک w رو اینجا استفاده کردیم. یعنی کاراکترهای کلمه رو جدا کن.</p>

<p>کدهای بخش سوم <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/1-Basics/03-RegEx.ipynb"><u>اینجا</u></a> قرار دارند.<br />
یک کار دیگه ای که می شه با این عبارات با قاعده انجام داد اینه که کلماتی که املاشون اشتباه نوشته شده در یک متن رو پیدا کرد و با مقدار درستش جایگزین کرد. مثال این مورد رو می تونید در <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/1-Basics/04-RegEx1.ipynb">اینجا</a> مشاهده کنید.</p>

<h2 id="بخش-چهارم-پیش-پردازش-پاکسازی-داده"><strong>بخش چهارم: پیش پردازش (پاکسازی) داده</strong></h2>

<p>برای اینکه داده آماده بررسی و تحلیل بشه باید یکسری مراحل به عنوان پیش پردازش روش انجام بشه تا مواردی که اضافه است حذف بشه. این مراحل شامل حذف علائم نگارشی، تقسیم جمله به کلمه ها متشکل، حذف کلماتی که معنی خاصی ندارندو حذف مشتقات کلمات می شود.</p>

<p>بریم پنج سطر اول دیتا رو دوباره ببینیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import pandas as pd
pd.set_option('display.max_colwidth', 100)
dataset = pd.read_csv('file_name', sep='\t', header=None)
dataset.columns = ['label', 'body']
dataset.head()
</code></pre></div></div>

<p>خط دوم <code class="language-plaintext highlighter-rouge">set_option('display.max_colwidth', 100)</code> تعداد کاراکترهایی که نمایش داده می شه رو مشخص می کنه. <br />
الان دیتا به این صورته:</p>

<p><img src="https://raw.githubusercontent.com/spacelover1/personalBlog/master/image/dataset.PNG" alt="dataset_before_cleaning" /></p>

<p>فایل دیتاست بعد از پاکسازی هم در این فولدر وجود داره و قراره دیتا به این صورت دربیاد:</p>

<p><img src="https://raw.githubusercontent.com/spacelover1/personalBlog/master/image/cleaned_dataset.PNG" alt="cleaned_dataset" /></p>

<h3 id="حذف-علائم-نگارشی"><strong>حذف علائم نگارشی</strong></h3>

<p>علائم نگارشی در کتابخونه <code class="language-plaintext highlighter-rouge">string</code> قرار دارند. باید یک تابع بنویسیم که این علائم نگارشی رو از متن پیام در دیتا حذف کنه. و متن بدون علائم نگارشی بده.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def remove_punct(text):
    text_nopunct = [char for char in text if char not in string.punctuation]
    return text_nopunct

dataset['body_nopunct'] = dataset['body'].apply(lambda x: remove_punct(x))
</code></pre></div></div>

<p>در اینجا چون متن پیام رو داره کاراکتر  به کاراکتر بررسی می کنه در نهایت هم کاراکتر ها رو از هم جدا می کنه و به عنوان خروجی می ده، برای اینکه به صورت کلمه خروجی بگیریم از تابع <code class="language-plaintext highlighter-rouge">join()</code> استفاده می کنیم.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>text_nopunct = "".join([char for char in text if char not in string.punctuation])
</code></pre></div></div>

<h3 id="جداسازی-کلمات"><strong>جداسازی کلمات</strong></h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import re
def tokenize(text):
    tokens = re.split('\W+', text)
    return tokens
    
dataset['body_tokenized'] = dataset['body_nopunct'].apply(lambda x: tokenize(x.lower()))
</code></pre></div></div>

<p>تابع <code class="language-plaintext highlighter-rouge">lower()</code> شاید اینجا زیاد استفاده نشه و اهمیتش مشخص نباشه ولی چون در پایتون حروف کوچک و بزرگ یکسان نیستند باید همه حروف در کلمات یک جور باشند.</p>

<h3 id="حذف-کلمات-بدون-معنی"><strong>حذف کلمات بدون معنی</strong></h3>

<p>هر زبانی یک سری کلمات داره که معنی خاصی در جمله ندارند و اگر حذف شوند جمله معنی خودش رو حفظ می کنه. مثل حروف ربط. با استفاده از کتابخانه <code class="language-plaintext highlighter-rouge">nltk</code> این کلمات رو از جمله حذف می کنیم:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import nltk
stopwords = nltk.corpus.stopwords.words('english')
</code></pre></div></div>

<p>حالا یک تابع می نویسیم که این کلمات رو حذف کنه از جملات:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def remove_stopwords(tokenized_list):
    text_nostop = [word for word in tokenized_list if word not in stopwords]
    return text_nostop

dataset['body_nostop'] = dataset['body_tokenized'].apply(lambda x: remove_stopwords(x))
</code></pre></div></div>

<p>کدهای بخش چهارم <a href="https://github.com/spacelover1/NLP-with-Python/blob/main/1-Basics/05-cleaning%20text_1.ipynb"><u>اینجا</u></a> قرار دارند.</p>

</div>]]>
    </content>
  </entry>

</feed>
